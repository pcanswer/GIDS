{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:  999\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "import torch.optim as optim\n",
    "import os\n",
    "# Set random seed for reproducibility\n",
    "manualSeed = 999\n",
    "#manualSeed = random.randint(1, 10000) # use if you want new results\n",
    "print(\"Random Seed: \", manualSeed)\n",
    "random.seed(manualSeed)\n",
    "torch.manual_seed(manualSeed)\n",
    "\n",
    "# Batch size during training\n",
    "batch_size = 64\n",
    "# Number of channels in the training images. For color images this is 3\n",
    "nc = 1\n",
    "# Size of z latent vector (i.e. size of generator input)\n",
    "nz = 20\n",
    "# Number of training epochs\n",
    "num_epochs = 10\n",
    "# Learning rate for optimizers\n",
    "lr = 0.1\n",
    "# Number of GPUs available. Use 0 for CPU mode.\n",
    "ngpu = 1\n",
    "\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "# custom weights initialization called on netG and netD\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.1)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "# Generator Code\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Generator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.layer1 = nn.ConvTranspose2d(nz, nz//2, 4, 2, 1, bias=False)\n",
    "        self.norm1 = nn.BatchNorm2d(nz//2,affine=True)\n",
    "        self.layer2 = nn.ConvTranspose2d(nz//2, nz//4, 4, 2, 1, bias=False)\n",
    "        self.norm2 = nn.BatchNorm2d(nz // 4,affine=True)\n",
    "        self.layer4 = nn.ConvTranspose2d(nz//4,1, 4, 2, 1, bias=False)\n",
    "        self.norm3 = nn.BatchNorm2d(1,affine=True)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.layer1(input)\n",
    "        out = self.norm1(out)\n",
    "        out = F.leaky_relu(out,0.2, inplace=True)\n",
    "        out = self.layer2(out)\n",
    "        out = self.norm2(out)\n",
    "        out = F.leaky_relu(out,0.2, inplace=True)\n",
    "        out = self.layer4(out)\n",
    "        out = self.norm3(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.layer1 = nn.Conv2d(1, nz//4, 4, 2, 1, bias=False)\n",
    "        self.norm1 = nn.BatchNorm2d(nz//4, affine=True)\n",
    "        self.layer2 = nn.Conv2d(nz//4, nz//2, 4, 2, 1, bias=False)\n",
    "        self.norm2 = nn.BatchNorm2d(nz//2, affine=True)\n",
    "        self.layer3 = nn.Conv2d(nz//2, nz, 4, 2, 1, bias=False)\n",
    "        self.norm3 = nn.BatchNorm2d(nz, affine=True)\n",
    "        self.layer4 = nn.Linear(nz*6*6,1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.layer1(input)\n",
    "        out = self.norm1(out)\n",
    "        out = F.leaky_relu(out,0.2, inplace=True)\n",
    "        out = self.layer2(out)\n",
    "        out = self.norm2(out)\n",
    "        out = F.leaky_relu(out,0.2, inplace=True)\n",
    "        out = self.layer3(out)\n",
    "        out = self.norm3(out)\n",
    "        out = F.leaky_relu(out, 0.2, inplace=True)\n",
    "        out = out.flatten(start_dim=1)\n",
    "        out = self.layer4(out)\n",
    "        out = torch.sigmoid(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Create the generator\n",
    "netG = Generator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netG.apply(weights_init)\n",
    "\n",
    "# Create the Discriminator\n",
    "netD = Discriminator(ngpu).to(device)\n",
    "\n",
    "# Handle multi-gpu if desired\n",
    "if (device.type == 'cuda') and (ngpu > 1):\n",
    "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "# Apply the weights_init function to randomly initialize all weights\n",
    "#  to mean=0, stdev=0.2.\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# Initialize BCELoss function\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "# Establish convention for real and fake labels during training\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "# Setup Adam optimizers for both G and D\n",
    "optimizerD = optim.SGD(netD.parameters(), lr=lr)\n",
    "optimizerG = optim.SGD(netG.parameters(), lr=lr)\n",
    "def train(net,data_loader,epoch,optimizer,criterion):\n",
    "    net.train()\n",
    "    for i in range(epoch):\n",
    "        for batch_id, (x_train, y_train) in enumerate(data_loader):\n",
    "            if x_train.shape[0] < 64:\n",
    "                continue\n",
    "            x_train = x_train.to(device)\n",
    "            y_train = y_train.to(device)\n",
    "            output = net(x_train)\n",
    "            y_train = y_train.reshape(-1,1)   # MSELoss\n",
    "            loss = criterion(output, y_train)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_id % 10 == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    i, batch_id * len(x_train), len(data_loader.dataset), 100. * batch_id / len(train_loader), loss.item()))\n",
    "\n",
    "def get_normal_data(model_test, test_data,threshold):\n",
    "    print(\"get_normal_data\")\n",
    "    normal_image = []\n",
    "    normal_image_label = []\n",
    "    test_output = model_test(test_data).detach().numpy().tolist()\n",
    "    test_data = test_data.detach().numpy().tolist()\n",
    "    for i in range(len(test_output)):\n",
    "        if test_output[i][0] > threshold:\n",
    "            normal_image.append(test_data[i])\n",
    "            normal_image_label.append(1)\n",
    "    features = torch.tensor(normal_image, dtype=torch.float32)\n",
    "    labels = torch.tensor(normal_image_label, dtype=torch.float32)\n",
    "    print('normal data num: ',features.shape)\n",
    "    normal_dataset = TensorDataset(features,labels)\n",
    "    return normal_dataset\n",
    "\n",
    "def distribution_calculate(model_test,test_data,test_label):\n",
    "    normal_total = 0\n",
    "    abnormal_total = 0\n",
    "    test_output = model_test(test_data).detach().numpy().tolist()\n",
    "    Y_test = test_label.numpy().tolist()\n",
    "    x_normal = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "    x_abnormal = [0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "    y_normal = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "    y_abnormal = [0,0,0,0,0,0,0,0,0,0,0]\n",
    "    for i in range(len(Y_test)):\n",
    "        if Y_test[i] == 0:\n",
    "            abnormal_total += 1\n",
    "            y_abnormal[math.floor(test_output[i][0]*10)] += 1\n",
    "        else:\n",
    "            normal_total += 1\n",
    "            y_normal[math.floor(test_output[i][0]*10)] += 1\n",
    "    print('normal: ',y_normal)\n",
    "    print('abnormal: ',y_abnormal)\n",
    "    plt.scatter(x_normal,y_normal,c='k')\n",
    "    plt.scatter(x_abnormal,y_abnormal,c='r')\n",
    "    plt.title('total number')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def test_p(model_test, test_data, test_label,threshold):\n",
    "    test_output = model_test(test_data).detach().numpy().tolist()\n",
    "    for i in range(len(test_output)):\n",
    "        if test_output[i][0] <= threshold:\n",
    "            test_output[i][0] = 0\n",
    "        else:\n",
    "            test_output[i][0] = 1\n",
    "    Y_test = test_label.numpy().tolist()\n",
    "    cm = confusion_matrix(Y_test, test_output)\n",
    "    print(classification_report(Y_test, test_output))\n",
    "    f,ax=plt.subplots(figsize=(2,2))\n",
    "    sns.heatmap(cm,annot=True,linewidth=0.1,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "    plt.xlabel(\"y_pred\")\n",
    "    plt.ylabel(\"y_true\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/64795 (0%)]\tLoss: 0.706165\n",
      "Train Epoch: 0 [640/64795 (1%)]\tLoss: 0.096504\n",
      "Train Epoch: 0 [1280/64795 (2%)]\tLoss: 0.012331\n",
      "Train Epoch: 0 [1920/64795 (3%)]\tLoss: 0.012578\n",
      "Train Epoch: 0 [2560/64795 (4%)]\tLoss: 0.021860\n",
      "Train Epoch: 0 [3200/64795 (5%)]\tLoss: 0.005216\n",
      "Train Epoch: 0 [3840/64795 (6%)]\tLoss: 0.003384\n",
      "Train Epoch: 0 [4480/64795 (7%)]\tLoss: 0.002762\n",
      "Train Epoch: 0 [5120/64795 (8%)]\tLoss: 0.003827\n",
      "Train Epoch: 0 [5760/64795 (9%)]\tLoss: 0.005658\n",
      "Train Epoch: 0 [6400/64795 (10%)]\tLoss: 0.002539\n",
      "Train Epoch: 0 [7040/64795 (11%)]\tLoss: 0.002968\n",
      "Train Epoch: 0 [7680/64795 (12%)]\tLoss: 0.007458\n",
      "Train Epoch: 0 [8320/64795 (13%)]\tLoss: 0.002964\n",
      "Train Epoch: 0 [8960/64795 (14%)]\tLoss: 0.001637\n",
      "Train Epoch: 0 [9600/64795 (15%)]\tLoss: 0.001814\n",
      "Train Epoch: 0 [10240/64795 (16%)]\tLoss: 0.001872\n",
      "Train Epoch: 0 [10880/64795 (17%)]\tLoss: 0.003313\n",
      "Train Epoch: 0 [11520/64795 (18%)]\tLoss: 0.001271\n",
      "Train Epoch: 0 [12160/64795 (19%)]\tLoss: 0.001295\n",
      "Train Epoch: 0 [12800/64795 (20%)]\tLoss: 0.004724\n",
      "Train Epoch: 0 [13440/64795 (21%)]\tLoss: 0.002131\n",
      "Train Epoch: 0 [14080/64795 (22%)]\tLoss: 0.005584\n",
      "Train Epoch: 0 [14720/64795 (23%)]\tLoss: 0.001926\n",
      "Train Epoch: 0 [15360/64795 (24%)]\tLoss: 0.001013\n",
      "Train Epoch: 0 [16000/64795 (25%)]\tLoss: 0.001564\n",
      "Train Epoch: 0 [16640/64795 (26%)]\tLoss: 0.008716\n",
      "Train Epoch: 0 [17280/64795 (27%)]\tLoss: 0.000891\n",
      "Train Epoch: 0 [17920/64795 (28%)]\tLoss: 0.000966\n",
      "Train Epoch: 0 [18560/64795 (29%)]\tLoss: 0.001097\n",
      "Train Epoch: 0 [19200/64795 (30%)]\tLoss: 0.002754\n",
      "Train Epoch: 0 [19840/64795 (31%)]\tLoss: 0.060520\n",
      "Train Epoch: 0 [20480/64795 (32%)]\tLoss: 0.002736\n",
      "Train Epoch: 0 [21120/64795 (33%)]\tLoss: 0.001544\n",
      "Train Epoch: 0 [21760/64795 (34%)]\tLoss: 0.002483\n",
      "Train Epoch: 0 [22400/64795 (35%)]\tLoss: 0.002254\n",
      "Train Epoch: 0 [23040/64795 (36%)]\tLoss: 0.002995\n",
      "Train Epoch: 0 [23680/64795 (37%)]\tLoss: 0.001685\n",
      "Train Epoch: 0 [24320/64795 (38%)]\tLoss: 0.001034\n",
      "Train Epoch: 0 [24960/64795 (38%)]\tLoss: 0.001553\n",
      "Train Epoch: 0 [25600/64795 (39%)]\tLoss: 0.002401\n",
      "Train Epoch: 0 [26240/64795 (40%)]\tLoss: 0.001110\n",
      "Train Epoch: 0 [26880/64795 (41%)]\tLoss: 0.039860\n",
      "Train Epoch: 0 [27520/64795 (42%)]\tLoss: 0.001153\n",
      "Train Epoch: 0 [28160/64795 (43%)]\tLoss: 0.001150\n",
      "Train Epoch: 0 [28800/64795 (44%)]\tLoss: 0.002539\n",
      "Train Epoch: 0 [29440/64795 (45%)]\tLoss: 0.000709\n",
      "Train Epoch: 0 [30080/64795 (46%)]\tLoss: 0.000995\n",
      "Train Epoch: 0 [30720/64795 (47%)]\tLoss: 0.001464\n",
      "Train Epoch: 0 [31360/64795 (48%)]\tLoss: 0.009055\n",
      "Train Epoch: 0 [32000/64795 (49%)]\tLoss: 0.045047\n",
      "Train Epoch: 0 [32640/64795 (50%)]\tLoss: 0.002513\n",
      "Train Epoch: 0 [33280/64795 (51%)]\tLoss: 0.001177\n",
      "Train Epoch: 0 [33920/64795 (52%)]\tLoss: 0.001529\n",
      "Train Epoch: 0 [34560/64795 (53%)]\tLoss: 0.001917\n",
      "Train Epoch: 0 [35200/64795 (54%)]\tLoss: 0.000977\n",
      "Train Epoch: 0 [35840/64795 (55%)]\tLoss: 0.002734\n",
      "Train Epoch: 0 [36480/64795 (56%)]\tLoss: 0.002768\n",
      "Train Epoch: 0 [37120/64795 (57%)]\tLoss: 0.000917\n",
      "Train Epoch: 0 [37760/64795 (58%)]\tLoss: 0.000665\n",
      "Train Epoch: 0 [38400/64795 (59%)]\tLoss: 0.000839\n",
      "Train Epoch: 0 [39040/64795 (60%)]\tLoss: 0.028300\n",
      "Train Epoch: 0 [39680/64795 (61%)]\tLoss: 0.002534\n",
      "Train Epoch: 0 [40320/64795 (62%)]\tLoss: 0.041994\n",
      "Train Epoch: 0 [40960/64795 (63%)]\tLoss: 0.001187\n",
      "Train Epoch: 0 [41600/64795 (64%)]\tLoss: 0.003501\n",
      "Train Epoch: 0 [42240/64795 (65%)]\tLoss: 0.001653\n",
      "Train Epoch: 0 [42880/64795 (66%)]\tLoss: 0.000875\n",
      "Train Epoch: 0 [43520/64795 (67%)]\tLoss: 0.000898\n",
      "Train Epoch: 0 [44160/64795 (68%)]\tLoss: 0.000929\n",
      "Train Epoch: 0 [44800/64795 (69%)]\tLoss: 0.007548\n",
      "Train Epoch: 0 [45440/64795 (70%)]\tLoss: 0.004110\n",
      "Train Epoch: 0 [46080/64795 (71%)]\tLoss: 0.008802\n",
      "Train Epoch: 0 [46720/64795 (72%)]\tLoss: 0.001484\n",
      "Train Epoch: 0 [47360/64795 (73%)]\tLoss: 0.002893\n",
      "Train Epoch: 0 [48000/64795 (74%)]\tLoss: 0.000884\n",
      "Train Epoch: 0 [48640/64795 (75%)]\tLoss: 0.002097\n",
      "Train Epoch: 0 [49280/64795 (76%)]\tLoss: 0.001634\n",
      "Train Epoch: 0 [49920/64795 (77%)]\tLoss: 0.002290\n",
      "Train Epoch: 0 [50560/64795 (78%)]\tLoss: 0.003245\n",
      "Train Epoch: 0 [51200/64795 (79%)]\tLoss: 0.001811\n",
      "Train Epoch: 0 [51840/64795 (80%)]\tLoss: 0.003517\n",
      "Train Epoch: 0 [52480/64795 (81%)]\tLoss: 0.082415\n",
      "Train Epoch: 0 [53120/64795 (82%)]\tLoss: 0.001581\n",
      "Train Epoch: 0 [53760/64795 (83%)]\tLoss: 0.002331\n",
      "Train Epoch: 0 [54400/64795 (84%)]\tLoss: 0.017064\n",
      "Train Epoch: 0 [55040/64795 (85%)]\tLoss: 0.001812\n",
      "Train Epoch: 0 [55680/64795 (86%)]\tLoss: 0.002070\n",
      "Train Epoch: 0 [56320/64795 (87%)]\tLoss: 0.000516\n",
      "Train Epoch: 0 [56960/64795 (88%)]\tLoss: 0.025907\n",
      "Train Epoch: 0 [57600/64795 (89%)]\tLoss: 0.000850\n",
      "Train Epoch: 0 [58240/64795 (90%)]\tLoss: 0.000563\n",
      "Train Epoch: 0 [58880/64795 (91%)]\tLoss: 0.000391\n",
      "Train Epoch: 0 [59520/64795 (92%)]\tLoss: 0.000459\n",
      "Train Epoch: 0 [60160/64795 (93%)]\tLoss: 0.000456\n",
      "Train Epoch: 0 [60800/64795 (94%)]\tLoss: 0.000409\n",
      "Train Epoch: 0 [61440/64795 (95%)]\tLoss: 0.000778\n",
      "Train Epoch: 0 [62080/64795 (96%)]\tLoss: 0.003518\n",
      "Train Epoch: 0 [62720/64795 (97%)]\tLoss: 0.001615\n",
      "Train Epoch: 0 [63360/64795 (98%)]\tLoss: 0.002002\n",
      "Train Epoch: 0 [64000/64795 (99%)]\tLoss: 0.131318\n",
      "Train Epoch: 0 [64640/64795 (100%)]\tLoss: 0.001105\n",
      "Train Epoch: 1 [0/64795 (0%)]\tLoss: 0.000970\n",
      "Train Epoch: 1 [640/64795 (1%)]\tLoss: 0.002428\n",
      "Train Epoch: 1 [1280/64795 (2%)]\tLoss: 0.000590\n",
      "Train Epoch: 1 [1920/64795 (3%)]\tLoss: 0.000675\n",
      "Train Epoch: 1 [2560/64795 (4%)]\tLoss: 0.001153\n",
      "Train Epoch: 1 [3200/64795 (5%)]\tLoss: 0.091235\n",
      "Train Epoch: 1 [3840/64795 (6%)]\tLoss: 0.001668\n",
      "Train Epoch: 1 [4480/64795 (7%)]\tLoss: 0.031592\n",
      "Train Epoch: 1 [5120/64795 (8%)]\tLoss: 0.029989\n",
      "Train Epoch: 1 [5760/64795 (9%)]\tLoss: 0.001238\n",
      "Train Epoch: 1 [6400/64795 (10%)]\tLoss: 0.000892\n",
      "Train Epoch: 1 [7040/64795 (11%)]\tLoss: 0.003724\n",
      "Train Epoch: 1 [7680/64795 (12%)]\tLoss: 0.001038\n",
      "Train Epoch: 1 [8320/64795 (13%)]\tLoss: 0.000886\n",
      "Train Epoch: 1 [8960/64795 (14%)]\tLoss: 0.000461\n",
      "Train Epoch: 1 [9600/64795 (15%)]\tLoss: 0.001667\n",
      "Train Epoch: 1 [10240/64795 (16%)]\tLoss: 0.004648\n",
      "Train Epoch: 1 [10880/64795 (17%)]\tLoss: 0.000826\n",
      "Train Epoch: 1 [11520/64795 (18%)]\tLoss: 0.002219\n",
      "Train Epoch: 1 [12160/64795 (19%)]\tLoss: 0.005068\n",
      "Train Epoch: 1 [12800/64795 (20%)]\tLoss: 0.004005\n",
      "Train Epoch: 1 [13440/64795 (21%)]\tLoss: 0.002170\n",
      "Train Epoch: 1 [14080/64795 (22%)]\tLoss: 0.001020\n",
      "Train Epoch: 1 [14720/64795 (23%)]\tLoss: 0.001150\n",
      "Train Epoch: 1 [15360/64795 (24%)]\tLoss: 0.000289\n",
      "Train Epoch: 1 [16000/64795 (25%)]\tLoss: 0.000817\n",
      "Train Epoch: 1 [16640/64795 (26%)]\tLoss: 0.000598\n",
      "Train Epoch: 1 [17280/64795 (27%)]\tLoss: 0.000629\n",
      "Train Epoch: 1 [17920/64795 (28%)]\tLoss: 0.000593\n",
      "Train Epoch: 1 [18560/64795 (29%)]\tLoss: 0.000431\n",
      "Train Epoch: 1 [19200/64795 (30%)]\tLoss: 0.000478\n",
      "Train Epoch: 1 [19840/64795 (31%)]\tLoss: 0.000581\n",
      "Train Epoch: 1 [20480/64795 (32%)]\tLoss: 0.083910\n",
      "Train Epoch: 1 [21120/64795 (33%)]\tLoss: 0.002534\n",
      "Train Epoch: 1 [21760/64795 (34%)]\tLoss: 0.000884\n",
      "Train Epoch: 1 [22400/64795 (35%)]\tLoss: 0.000383\n",
      "Train Epoch: 1 [23040/64795 (36%)]\tLoss: 0.006379\n",
      "Train Epoch: 1 [23680/64795 (37%)]\tLoss: 0.010923\n",
      "Train Epoch: 1 [24320/64795 (38%)]\tLoss: 0.000749\n",
      "Train Epoch: 1 [24960/64795 (38%)]\tLoss: 0.001521\n",
      "Train Epoch: 1 [25600/64795 (39%)]\tLoss: 0.001563\n",
      "Train Epoch: 1 [26240/64795 (40%)]\tLoss: 0.000449\n",
      "Train Epoch: 1 [26880/64795 (41%)]\tLoss: 0.000888\n",
      "Train Epoch: 1 [27520/64795 (42%)]\tLoss: 0.001287\n",
      "Train Epoch: 1 [28160/64795 (43%)]\tLoss: 0.005359\n",
      "Train Epoch: 1 [28800/64795 (44%)]\tLoss: 0.001712\n",
      "Train Epoch: 1 [29440/64795 (45%)]\tLoss: 0.001005\n",
      "Train Epoch: 1 [30080/64795 (46%)]\tLoss: 0.000854\n",
      "Train Epoch: 1 [30720/64795 (47%)]\tLoss: 0.120206\n",
      "Train Epoch: 1 [31360/64795 (48%)]\tLoss: 0.000981\n",
      "Train Epoch: 1 [32000/64795 (49%)]\tLoss: 0.000803\n",
      "Train Epoch: 1 [32640/64795 (50%)]\tLoss: 0.000660\n",
      "Train Epoch: 1 [33280/64795 (51%)]\tLoss: 0.000452\n",
      "Train Epoch: 1 [33920/64795 (52%)]\tLoss: 0.002176\n",
      "Train Epoch: 1 [34560/64795 (53%)]\tLoss: 0.001084\n",
      "Train Epoch: 1 [35200/64795 (54%)]\tLoss: 0.001523\n",
      "Train Epoch: 1 [35840/64795 (55%)]\tLoss: 0.000474\n",
      "Train Epoch: 1 [36480/64795 (56%)]\tLoss: 0.000510\n",
      "Train Epoch: 1 [37120/64795 (57%)]\tLoss: 0.000619\n",
      "Train Epoch: 1 [37760/64795 (58%)]\tLoss: 0.000492\n",
      "Train Epoch: 1 [38400/64795 (59%)]\tLoss: 0.000317\n",
      "Train Epoch: 1 [39040/64795 (60%)]\tLoss: 0.000480\n",
      "Train Epoch: 1 [39680/64795 (61%)]\tLoss: 0.000795\n",
      "Train Epoch: 1 [40320/64795 (62%)]\tLoss: 0.000507\n",
      "Train Epoch: 1 [40960/64795 (63%)]\tLoss: 0.002126\n",
      "Train Epoch: 1 [41600/64795 (64%)]\tLoss: 0.000972\n",
      "Train Epoch: 1 [42240/64795 (65%)]\tLoss: 0.000322\n",
      "Train Epoch: 1 [42880/64795 (66%)]\tLoss: 0.001788\n",
      "Train Epoch: 1 [43520/64795 (67%)]\tLoss: 0.000667\n",
      "Train Epoch: 1 [44160/64795 (68%)]\tLoss: 0.001002\n",
      "Train Epoch: 1 [44800/64795 (69%)]\tLoss: 0.006224\n",
      "Train Epoch: 1 [45440/64795 (70%)]\tLoss: 0.001112\n",
      "Train Epoch: 1 [46080/64795 (71%)]\tLoss: 0.002155\n",
      "Train Epoch: 1 [46720/64795 (72%)]\tLoss: 0.000862\n",
      "Train Epoch: 1 [47360/64795 (73%)]\tLoss: 0.001387\n",
      "Train Epoch: 1 [48000/64795 (74%)]\tLoss: 0.040409\n",
      "Train Epoch: 1 [48640/64795 (75%)]\tLoss: 0.001138\n",
      "Train Epoch: 1 [49280/64795 (76%)]\tLoss: 0.000887\n",
      "Train Epoch: 1 [49920/64795 (77%)]\tLoss: 0.000463\n",
      "Train Epoch: 1 [50560/64795 (78%)]\tLoss: 0.000823\n",
      "Train Epoch: 1 [51200/64795 (79%)]\tLoss: 0.001355\n",
      "Train Epoch: 1 [51840/64795 (80%)]\tLoss: 0.001937\n",
      "Train Epoch: 1 [52480/64795 (81%)]\tLoss: 0.001764\n",
      "Train Epoch: 1 [53120/64795 (82%)]\tLoss: 0.000642\n",
      "Train Epoch: 1 [53760/64795 (83%)]\tLoss: 0.000555\n",
      "Train Epoch: 1 [54400/64795 (84%)]\tLoss: 0.000699\n",
      "Train Epoch: 1 [55040/64795 (85%)]\tLoss: 0.001494\n",
      "Train Epoch: 1 [55680/64795 (86%)]\tLoss: 0.000985\n",
      "Train Epoch: 1 [56320/64795 (87%)]\tLoss: 0.000374\n",
      "Train Epoch: 1 [56960/64795 (88%)]\tLoss: 0.000400\n",
      "Train Epoch: 1 [57600/64795 (89%)]\tLoss: 0.000440\n",
      "Train Epoch: 1 [58240/64795 (90%)]\tLoss: 0.000546\n",
      "Train Epoch: 1 [58880/64795 (91%)]\tLoss: 0.004204\n",
      "Train Epoch: 1 [59520/64795 (92%)]\tLoss: 0.036581\n",
      "Train Epoch: 1 [60160/64795 (93%)]\tLoss: 0.000851\n",
      "Train Epoch: 1 [60800/64795 (94%)]\tLoss: 0.002271\n",
      "Train Epoch: 1 [61440/64795 (95%)]\tLoss: 0.001048\n",
      "Train Epoch: 1 [62080/64795 (96%)]\tLoss: 0.005904\n",
      "Train Epoch: 1 [62720/64795 (97%)]\tLoss: 0.001381\n",
      "Train Epoch: 1 [63360/64795 (98%)]\tLoss: 0.000564\n",
      "Train Epoch: 1 [64000/64795 (99%)]\tLoss: 0.000444\n",
      "Train Epoch: 1 [64640/64795 (100%)]\tLoss: 0.001796\n",
      "Train Epoch: 2 [0/64795 (0%)]\tLoss: 0.003220\n",
      "Train Epoch: 2 [640/64795 (1%)]\tLoss: 0.001382\n",
      "Train Epoch: 2 [1280/64795 (2%)]\tLoss: 0.001185\n",
      "Train Epoch: 2 [1920/64795 (3%)]\tLoss: 0.062044\n",
      "Train Epoch: 2 [2560/64795 (4%)]\tLoss: 0.001781\n",
      "Train Epoch: 2 [3200/64795 (5%)]\tLoss: 0.001508\n",
      "Train Epoch: 2 [3840/64795 (6%)]\tLoss: 0.001789\n",
      "Train Epoch: 2 [4480/64795 (7%)]\tLoss: 0.001084\n",
      "Train Epoch: 2 [5120/64795 (8%)]\tLoss: 0.001384\n",
      "Train Epoch: 2 [5760/64795 (9%)]\tLoss: 0.000662\n",
      "Train Epoch: 2 [6400/64795 (10%)]\tLoss: 0.001100\n",
      "Train Epoch: 2 [7040/64795 (11%)]\tLoss: 0.000571\n",
      "Train Epoch: 2 [7680/64795 (12%)]\tLoss: 0.001145\n",
      "Train Epoch: 2 [8320/64795 (13%)]\tLoss: 0.001121\n",
      "Train Epoch: 2 [8960/64795 (14%)]\tLoss: 0.000276\n",
      "Train Epoch: 2 [9600/64795 (15%)]\tLoss: 0.000805\n",
      "Train Epoch: 2 [10240/64795 (16%)]\tLoss: 0.000552\n",
      "Train Epoch: 2 [10880/64795 (17%)]\tLoss: 0.000256\n",
      "Train Epoch: 2 [11520/64795 (18%)]\tLoss: 0.000287\n",
      "Train Epoch: 2 [12160/64795 (19%)]\tLoss: 0.001065\n",
      "Train Epoch: 2 [12800/64795 (20%)]\tLoss: 0.000519\n",
      "Train Epoch: 2 [13440/64795 (21%)]\tLoss: 0.001997\n",
      "Train Epoch: 2 [14080/64795 (22%)]\tLoss: 0.000810\n",
      "Train Epoch: 2 [14720/64795 (23%)]\tLoss: 0.000653\n",
      "Train Epoch: 2 [15360/64795 (24%)]\tLoss: 0.001307\n",
      "Train Epoch: 2 [16000/64795 (25%)]\tLoss: 0.066761\n",
      "Train Epoch: 2 [16640/64795 (26%)]\tLoss: 0.000274\n",
      "Train Epoch: 2 [17280/64795 (27%)]\tLoss: 0.000722\n",
      "Train Epoch: 2 [17920/64795 (28%)]\tLoss: 0.000877\n",
      "Train Epoch: 2 [18560/64795 (29%)]\tLoss: 0.000686\n",
      "Train Epoch: 2 [19200/64795 (30%)]\tLoss: 0.000539\n",
      "Train Epoch: 2 [19840/64795 (31%)]\tLoss: 0.000951\n",
      "Train Epoch: 2 [20480/64795 (32%)]\tLoss: 0.000686\n",
      "Train Epoch: 2 [21120/64795 (33%)]\tLoss: 0.000536\n",
      "Train Epoch: 2 [21760/64795 (34%)]\tLoss: 0.002354\n",
      "Train Epoch: 2 [22400/64795 (35%)]\tLoss: 0.000787\n",
      "Train Epoch: 2 [23040/64795 (36%)]\tLoss: 0.000835\n",
      "Train Epoch: 2 [23680/64795 (37%)]\tLoss: 0.004933\n",
      "Train Epoch: 2 [24320/64795 (38%)]\tLoss: 0.000373\n",
      "Train Epoch: 2 [24960/64795 (38%)]\tLoss: 0.000812\n",
      "Train Epoch: 2 [25600/64795 (39%)]\tLoss: 0.027105\n",
      "Train Epoch: 2 [26240/64795 (40%)]\tLoss: 0.001535\n",
      "Train Epoch: 2 [26880/64795 (41%)]\tLoss: 0.000595\n",
      "Train Epoch: 2 [27520/64795 (42%)]\tLoss: 0.003710\n",
      "Train Epoch: 2 [28160/64795 (43%)]\tLoss: 0.000740\n",
      "Train Epoch: 2 [28800/64795 (44%)]\tLoss: 0.068409\n",
      "Train Epoch: 2 [29440/64795 (45%)]\tLoss: 0.000738\n",
      "Train Epoch: 2 [30080/64795 (46%)]\tLoss: 0.001286\n",
      "Train Epoch: 2 [30720/64795 (47%)]\tLoss: 0.001298\n",
      "Train Epoch: 2 [31360/64795 (48%)]\tLoss: 0.030357\n",
      "Train Epoch: 2 [32000/64795 (49%)]\tLoss: 0.001236\n",
      "Train Epoch: 2 [32640/64795 (50%)]\tLoss: 0.001657\n",
      "Train Epoch: 2 [33280/64795 (51%)]\tLoss: 0.002304\n",
      "Train Epoch: 2 [33920/64795 (52%)]\tLoss: 0.002505\n",
      "Train Epoch: 2 [34560/64795 (53%)]\tLoss: 0.055772\n",
      "Train Epoch: 2 [35200/64795 (54%)]\tLoss: 0.002857\n",
      "Train Epoch: 2 [35840/64795 (55%)]\tLoss: 0.000609\n",
      "Train Epoch: 2 [36480/64795 (56%)]\tLoss: 0.000313\n",
      "Train Epoch: 2 [37120/64795 (57%)]\tLoss: 0.004327\n",
      "Train Epoch: 2 [37760/64795 (58%)]\tLoss: 0.000592\n",
      "Train Epoch: 2 [38400/64795 (59%)]\tLoss: 0.000578\n",
      "Train Epoch: 2 [39040/64795 (60%)]\tLoss: 0.001899\n",
      "Train Epoch: 2 [39680/64795 (61%)]\tLoss: 0.001779\n",
      "Train Epoch: 2 [40320/64795 (62%)]\tLoss: 0.000515\n",
      "Train Epoch: 2 [40960/64795 (63%)]\tLoss: 0.000419\n",
      "Train Epoch: 2 [41600/64795 (64%)]\tLoss: 0.000694\n",
      "Train Epoch: 2 [42240/64795 (65%)]\tLoss: 0.000661\n",
      "Train Epoch: 2 [42880/64795 (66%)]\tLoss: 0.000369\n",
      "Train Epoch: 2 [43520/64795 (67%)]\tLoss: 0.000523\n",
      "Train Epoch: 2 [44160/64795 (68%)]\tLoss: 0.000985\n",
      "Train Epoch: 2 [44800/64795 (69%)]\tLoss: 0.006551\n",
      "Train Epoch: 2 [45440/64795 (70%)]\tLoss: 0.000683\n",
      "Train Epoch: 2 [46080/64795 (71%)]\tLoss: 0.001609\n",
      "Train Epoch: 2 [46720/64795 (72%)]\tLoss: 0.005030\n",
      "Train Epoch: 2 [47360/64795 (73%)]\tLoss: 0.000667\n",
      "Train Epoch: 2 [48000/64795 (74%)]\tLoss: 0.001298\n",
      "Train Epoch: 2 [48640/64795 (75%)]\tLoss: 0.069406\n",
      "Train Epoch: 2 [49280/64795 (76%)]\tLoss: 0.000798\n",
      "Train Epoch: 2 [49920/64795 (77%)]\tLoss: 0.000589\n",
      "Train Epoch: 2 [50560/64795 (78%)]\tLoss: 0.000700\n",
      "Train Epoch: 2 [51200/64795 (79%)]\tLoss: 0.000780\n",
      "Train Epoch: 2 [51840/64795 (80%)]\tLoss: 0.091218\n",
      "Train Epoch: 2 [52480/64795 (81%)]\tLoss: 0.106216\n",
      "Train Epoch: 2 [53120/64795 (82%)]\tLoss: 0.002418\n",
      "Train Epoch: 2 [53760/64795 (83%)]\tLoss: 0.000853\n",
      "Train Epoch: 2 [54400/64795 (84%)]\tLoss: 0.000681\n",
      "Train Epoch: 2 [55040/64795 (85%)]\tLoss: 0.000740\n",
      "Train Epoch: 2 [55680/64795 (86%)]\tLoss: 0.001324\n",
      "Train Epoch: 2 [56320/64795 (87%)]\tLoss: 0.001603\n",
      "Train Epoch: 2 [56960/64795 (88%)]\tLoss: 0.001236\n",
      "Train Epoch: 2 [57600/64795 (89%)]\tLoss: 0.000582\n",
      "Train Epoch: 2 [58240/64795 (90%)]\tLoss: 0.000244\n",
      "Train Epoch: 2 [58880/64795 (91%)]\tLoss: 0.000621\n",
      "Train Epoch: 2 [59520/64795 (92%)]\tLoss: 0.000301\n",
      "Train Epoch: 2 [60160/64795 (93%)]\tLoss: 0.000598\n",
      "Train Epoch: 2 [60800/64795 (94%)]\tLoss: 0.003380\n",
      "Train Epoch: 2 [61440/64795 (95%)]\tLoss: 0.000279\n",
      "Train Epoch: 2 [62080/64795 (96%)]\tLoss: 0.001938\n",
      "Train Epoch: 2 [62720/64795 (97%)]\tLoss: 0.000442\n",
      "Train Epoch: 2 [63360/64795 (98%)]\tLoss: 0.000479\n",
      "Train Epoch: 2 [64000/64795 (99%)]\tLoss: 0.000341\n",
      "Train Epoch: 2 [64640/64795 (100%)]\tLoss: 0.000344\n",
      "Train Epoch: 3 [0/64795 (0%)]\tLoss: 0.000352\n",
      "Train Epoch: 3 [640/64795 (1%)]\tLoss: 0.000348\n",
      "Train Epoch: 3 [1280/64795 (2%)]\tLoss: 0.000345\n",
      "Train Epoch: 3 [1920/64795 (3%)]\tLoss: 0.000264\n",
      "Train Epoch: 3 [2560/64795 (4%)]\tLoss: 0.000887\n",
      "Train Epoch: 3 [3200/64795 (5%)]\tLoss: 0.000624\n",
      "Train Epoch: 3 [3840/64795 (6%)]\tLoss: 0.000684\n",
      "Train Epoch: 3 [4480/64795 (7%)]\tLoss: 0.000743\n",
      "Train Epoch: 3 [5120/64795 (8%)]\tLoss: 0.000835\n",
      "Train Epoch: 3 [5760/64795 (9%)]\tLoss: 0.000469\n",
      "Train Epoch: 3 [6400/64795 (10%)]\tLoss: 0.003212\n",
      "Train Epoch: 3 [7040/64795 (11%)]\tLoss: 0.002131\n",
      "Train Epoch: 3 [7680/64795 (12%)]\tLoss: 0.000557\n",
      "Train Epoch: 3 [8320/64795 (13%)]\tLoss: 0.001094\n",
      "Train Epoch: 3 [8960/64795 (14%)]\tLoss: 0.000857\n",
      "Train Epoch: 3 [9600/64795 (15%)]\tLoss: 0.000598\n",
      "Train Epoch: 3 [10240/64795 (16%)]\tLoss: 0.000304\n",
      "Train Epoch: 3 [10880/64795 (17%)]\tLoss: 0.000579\n",
      "Train Epoch: 3 [11520/64795 (18%)]\tLoss: 0.000730\n",
      "Train Epoch: 3 [12160/64795 (19%)]\tLoss: 0.001065\n",
      "Train Epoch: 3 [12800/64795 (20%)]\tLoss: 0.001278\n",
      "Train Epoch: 3 [13440/64795 (21%)]\tLoss: 0.000430\n",
      "Train Epoch: 3 [14080/64795 (22%)]\tLoss: 0.000748\n",
      "Train Epoch: 3 [14720/64795 (23%)]\tLoss: 0.000754\n",
      "Train Epoch: 3 [15360/64795 (24%)]\tLoss: 0.000622\n",
      "Train Epoch: 3 [16000/64795 (25%)]\tLoss: 0.000540\n",
      "Train Epoch: 3 [16640/64795 (26%)]\tLoss: 0.000343\n",
      "Train Epoch: 3 [17280/64795 (27%)]\tLoss: 0.000192\n",
      "Train Epoch: 3 [17920/64795 (28%)]\tLoss: 0.000183\n",
      "Train Epoch: 3 [18560/64795 (29%)]\tLoss: 0.006630\n",
      "Train Epoch: 3 [19200/64795 (30%)]\tLoss: 0.002334\n",
      "Train Epoch: 3 [19840/64795 (31%)]\tLoss: 0.005195\n",
      "Train Epoch: 3 [20480/64795 (32%)]\tLoss: 0.000522\n",
      "Train Epoch: 3 [21120/64795 (33%)]\tLoss: 0.001039\n",
      "Train Epoch: 3 [21760/64795 (34%)]\tLoss: 0.000496\n",
      "Train Epoch: 3 [22400/64795 (35%)]\tLoss: 0.001145\n",
      "Train Epoch: 3 [23040/64795 (36%)]\tLoss: 0.000609\n",
      "Train Epoch: 3 [23680/64795 (37%)]\tLoss: 0.001775\n",
      "Train Epoch: 3 [24320/64795 (38%)]\tLoss: 0.100018\n",
      "Train Epoch: 3 [24960/64795 (38%)]\tLoss: 0.001083\n",
      "Train Epoch: 3 [25600/64795 (39%)]\tLoss: 0.001076\n",
      "Train Epoch: 3 [26240/64795 (40%)]\tLoss: 0.000966\n",
      "Train Epoch: 3 [26880/64795 (41%)]\tLoss: 0.000642\n",
      "Train Epoch: 3 [27520/64795 (42%)]\tLoss: 0.000649\n",
      "Train Epoch: 3 [28160/64795 (43%)]\tLoss: 0.001544\n",
      "Train Epoch: 3 [28800/64795 (44%)]\tLoss: 0.001157\n",
      "Train Epoch: 3 [29440/64795 (45%)]\tLoss: 0.000570\n",
      "Train Epoch: 3 [30080/64795 (46%)]\tLoss: 0.000389\n",
      "Train Epoch: 3 [30720/64795 (47%)]\tLoss: 0.000470\n",
      "Train Epoch: 3 [31360/64795 (48%)]\tLoss: 0.000249\n",
      "Train Epoch: 3 [32000/64795 (49%)]\tLoss: 0.000440\n",
      "Train Epoch: 3 [32640/64795 (50%)]\tLoss: 0.000506\n",
      "Train Epoch: 3 [33280/64795 (51%)]\tLoss: 0.001711\n",
      "Train Epoch: 3 [33920/64795 (52%)]\tLoss: 0.000486\n",
      "Train Epoch: 3 [34560/64795 (53%)]\tLoss: 0.000471\n",
      "Train Epoch: 3 [35200/64795 (54%)]\tLoss: 0.000295\n",
      "Train Epoch: 3 [35840/64795 (55%)]\tLoss: 0.000269\n",
      "Train Epoch: 3 [36480/64795 (56%)]\tLoss: 0.000778\n",
      "Train Epoch: 3 [37120/64795 (57%)]\tLoss: 0.001615\n",
      "Train Epoch: 3 [37760/64795 (58%)]\tLoss: 0.000501\n",
      "Train Epoch: 3 [38400/64795 (59%)]\tLoss: 0.001631\n",
      "Train Epoch: 3 [39040/64795 (60%)]\tLoss: 0.001599\n",
      "Train Epoch: 3 [39680/64795 (61%)]\tLoss: 0.001039\n",
      "Train Epoch: 3 [40320/64795 (62%)]\tLoss: 0.001930\n",
      "Train Epoch: 3 [40960/64795 (63%)]\tLoss: 0.000248\n",
      "Train Epoch: 3 [41600/64795 (64%)]\tLoss: 0.000204\n",
      "Train Epoch: 3 [42240/64795 (65%)]\tLoss: 0.000350\n",
      "Train Epoch: 3 [42880/64795 (66%)]\tLoss: 0.000202\n",
      "Train Epoch: 3 [43520/64795 (67%)]\tLoss: 0.000526\n",
      "Train Epoch: 3 [44160/64795 (68%)]\tLoss: 0.000324\n",
      "Train Epoch: 3 [44800/64795 (69%)]\tLoss: 0.000440\n",
      "Train Epoch: 3 [45440/64795 (70%)]\tLoss: 0.000217\n",
      "Train Epoch: 3 [46080/64795 (71%)]\tLoss: 0.000179\n",
      "Train Epoch: 3 [46720/64795 (72%)]\tLoss: 0.000803\n",
      "Train Epoch: 3 [47360/64795 (73%)]\tLoss: 0.000329\n",
      "Train Epoch: 3 [48000/64795 (74%)]\tLoss: 0.000367\n",
      "Train Epoch: 3 [48640/64795 (75%)]\tLoss: 0.000463\n",
      "Train Epoch: 3 [49280/64795 (76%)]\tLoss: 0.001081\n",
      "Train Epoch: 3 [49920/64795 (77%)]\tLoss: 0.006382\n",
      "Train Epoch: 3 [50560/64795 (78%)]\tLoss: 0.000417\n",
      "Train Epoch: 3 [51200/64795 (79%)]\tLoss: 0.000562\n",
      "Train Epoch: 3 [51840/64795 (80%)]\tLoss: 0.000711\n",
      "Train Epoch: 3 [52480/64795 (81%)]\tLoss: 0.000364\n",
      "Train Epoch: 3 [53120/64795 (82%)]\tLoss: 0.000354\n",
      "Train Epoch: 3 [53760/64795 (83%)]\tLoss: 0.001134\n",
      "Train Epoch: 3 [54400/64795 (84%)]\tLoss: 0.095344\n",
      "Train Epoch: 3 [55040/64795 (85%)]\tLoss: 0.000630\n",
      "Train Epoch: 3 [55680/64795 (86%)]\tLoss: 0.000259\n",
      "Train Epoch: 3 [56320/64795 (87%)]\tLoss: 0.000796\n",
      "Train Epoch: 3 [56960/64795 (88%)]\tLoss: 0.000671\n",
      "Train Epoch: 3 [57600/64795 (89%)]\tLoss: 0.001244\n",
      "Train Epoch: 3 [58240/64795 (90%)]\tLoss: 0.000649\n",
      "Train Epoch: 3 [58880/64795 (91%)]\tLoss: 0.000685\n",
      "Train Epoch: 3 [59520/64795 (92%)]\tLoss: 0.001410\n",
      "Train Epoch: 3 [60160/64795 (93%)]\tLoss: 0.001183\n",
      "Train Epoch: 3 [60800/64795 (94%)]\tLoss: 0.000686\n",
      "Train Epoch: 3 [61440/64795 (95%)]\tLoss: 0.003236\n",
      "Train Epoch: 3 [62080/64795 (96%)]\tLoss: 0.001970\n",
      "Train Epoch: 3 [62720/64795 (97%)]\tLoss: 0.000345\n",
      "Train Epoch: 3 [63360/64795 (98%)]\tLoss: 0.000441\n",
      "Train Epoch: 3 [64000/64795 (99%)]\tLoss: 0.000409\n",
      "Train Epoch: 3 [64640/64795 (100%)]\tLoss: 0.022651\n",
      "Train Epoch: 4 [0/64795 (0%)]\tLoss: 0.004361\n",
      "Train Epoch: 4 [640/64795 (1%)]\tLoss: 0.002206\n",
      "Train Epoch: 4 [1280/64795 (2%)]\tLoss: 0.000429\n",
      "Train Epoch: 4 [1920/64795 (3%)]\tLoss: 0.057980\n",
      "Train Epoch: 4 [2560/64795 (4%)]\tLoss: 0.000579\n",
      "Train Epoch: 4 [3200/64795 (5%)]\tLoss: 0.000515\n",
      "Train Epoch: 4 [3840/64795 (6%)]\tLoss: 0.003720\n",
      "Train Epoch: 4 [4480/64795 (7%)]\tLoss: 0.001110\n",
      "Train Epoch: 4 [5120/64795 (8%)]\tLoss: 0.000730\n",
      "Train Epoch: 4 [5760/64795 (9%)]\tLoss: 0.000695\n",
      "Train Epoch: 4 [6400/64795 (10%)]\tLoss: 0.000278\n",
      "Train Epoch: 4 [7040/64795 (11%)]\tLoss: 0.000635\n",
      "Train Epoch: 4 [7680/64795 (12%)]\tLoss: 0.000906\n",
      "Train Epoch: 4 [8320/64795 (13%)]\tLoss: 0.000304\n",
      "Train Epoch: 4 [8960/64795 (14%)]\tLoss: 0.000464\n",
      "Train Epoch: 4 [9600/64795 (15%)]\tLoss: 0.000172\n",
      "Train Epoch: 4 [10240/64795 (16%)]\tLoss: 0.000351\n",
      "Train Epoch: 4 [10880/64795 (17%)]\tLoss: 0.000351\n",
      "Train Epoch: 4 [11520/64795 (18%)]\tLoss: 0.000459\n",
      "Train Epoch: 4 [12160/64795 (19%)]\tLoss: 0.000642\n",
      "Train Epoch: 4 [12800/64795 (20%)]\tLoss: 0.000261\n",
      "Train Epoch: 4 [13440/64795 (21%)]\tLoss: 0.001072\n",
      "Train Epoch: 4 [14080/64795 (22%)]\tLoss: 0.003227\n",
      "Train Epoch: 4 [14720/64795 (23%)]\tLoss: 0.000434\n",
      "Train Epoch: 4 [15360/64795 (24%)]\tLoss: 0.000797\n",
      "Train Epoch: 4 [16000/64795 (25%)]\tLoss: 0.001263\n",
      "Train Epoch: 4 [16640/64795 (26%)]\tLoss: 0.000586\n",
      "Train Epoch: 4 [17280/64795 (27%)]\tLoss: 0.001441\n",
      "Train Epoch: 4 [17920/64795 (28%)]\tLoss: 0.000717\n",
      "Train Epoch: 4 [18560/64795 (29%)]\tLoss: 0.000756\n",
      "Train Epoch: 4 [19200/64795 (30%)]\tLoss: 0.000182\n",
      "Train Epoch: 4 [19840/64795 (31%)]\tLoss: 0.000252\n",
      "Train Epoch: 4 [20480/64795 (32%)]\tLoss: 0.002334\n",
      "Train Epoch: 4 [21120/64795 (33%)]\tLoss: 0.000174\n",
      "Train Epoch: 4 [21760/64795 (34%)]\tLoss: 0.000434\n",
      "Train Epoch: 4 [22400/64795 (35%)]\tLoss: 0.000351\n",
      "Train Epoch: 4 [23040/64795 (36%)]\tLoss: 0.000484\n",
      "Train Epoch: 4 [23680/64795 (37%)]\tLoss: 0.000715\n",
      "Train Epoch: 4 [24320/64795 (38%)]\tLoss: 0.000481\n",
      "Train Epoch: 4 [24960/64795 (38%)]\tLoss: 0.000417\n",
      "Train Epoch: 4 [25600/64795 (39%)]\tLoss: 0.001095\n",
      "Train Epoch: 4 [26240/64795 (40%)]\tLoss: 0.001066\n",
      "Train Epoch: 4 [26880/64795 (41%)]\tLoss: 0.001459\n",
      "Train Epoch: 4 [27520/64795 (42%)]\tLoss: 0.000448\n",
      "Train Epoch: 4 [28160/64795 (43%)]\tLoss: 0.069858\n",
      "Train Epoch: 4 [28800/64795 (44%)]\tLoss: 0.025177\n",
      "Train Epoch: 4 [29440/64795 (45%)]\tLoss: 0.000995\n",
      "Train Epoch: 4 [30080/64795 (46%)]\tLoss: 0.000713\n",
      "Train Epoch: 4 [30720/64795 (47%)]\tLoss: 0.001501\n",
      "Train Epoch: 4 [31360/64795 (48%)]\tLoss: 0.000278\n",
      "Train Epoch: 4 [32000/64795 (49%)]\tLoss: 0.000140\n",
      "Train Epoch: 4 [32640/64795 (50%)]\tLoss: 0.000681\n",
      "Train Epoch: 4 [33280/64795 (51%)]\tLoss: 0.000342\n",
      "Train Epoch: 4 [33920/64795 (52%)]\tLoss: 0.000535\n",
      "Train Epoch: 4 [34560/64795 (53%)]\tLoss: 0.000339\n",
      "Train Epoch: 4 [35200/64795 (54%)]\tLoss: 0.000293\n",
      "Train Epoch: 4 [35840/64795 (55%)]\tLoss: 0.004101\n",
      "Train Epoch: 4 [36480/64795 (56%)]\tLoss: 0.098272\n",
      "Train Epoch: 4 [37120/64795 (57%)]\tLoss: 0.000800\n",
      "Train Epoch: 4 [37760/64795 (58%)]\tLoss: 0.000966\n",
      "Train Epoch: 4 [38400/64795 (59%)]\tLoss: 0.000263\n",
      "Train Epoch: 4 [39040/64795 (60%)]\tLoss: 0.000702\n",
      "Train Epoch: 4 [39680/64795 (61%)]\tLoss: 0.000346\n",
      "Train Epoch: 4 [40320/64795 (62%)]\tLoss: 0.000596\n",
      "Train Epoch: 4 [40960/64795 (63%)]\tLoss: 0.000617\n",
      "Train Epoch: 4 [41600/64795 (64%)]\tLoss: 0.000297\n",
      "Train Epoch: 4 [42240/64795 (65%)]\tLoss: 0.000599\n",
      "Train Epoch: 4 [42880/64795 (66%)]\tLoss: 0.001780\n",
      "Train Epoch: 4 [43520/64795 (67%)]\tLoss: 0.000693\n",
      "Train Epoch: 4 [44160/64795 (68%)]\tLoss: 0.001998\n",
      "Train Epoch: 4 [44800/64795 (69%)]\tLoss: 0.000868\n",
      "Train Epoch: 4 [45440/64795 (70%)]\tLoss: 0.000563\n",
      "Train Epoch: 4 [46080/64795 (71%)]\tLoss: 0.000403\n",
      "Train Epoch: 4 [46720/64795 (72%)]\tLoss: 0.000910\n",
      "Train Epoch: 4 [47360/64795 (73%)]\tLoss: 0.000207\n",
      "Train Epoch: 4 [48000/64795 (74%)]\tLoss: 0.000432\n",
      "Train Epoch: 4 [48640/64795 (75%)]\tLoss: 0.000113\n",
      "Train Epoch: 4 [49280/64795 (76%)]\tLoss: 0.004012\n",
      "Train Epoch: 4 [49920/64795 (77%)]\tLoss: 0.000479\n",
      "Train Epoch: 4 [50560/64795 (78%)]\tLoss: 0.000874\n",
      "Train Epoch: 4 [51200/64795 (79%)]\tLoss: 0.000866\n",
      "Train Epoch: 4 [51840/64795 (80%)]\tLoss: 0.012136\n",
      "Train Epoch: 4 [52480/64795 (81%)]\tLoss: 0.000498\n",
      "Train Epoch: 4 [53120/64795 (82%)]\tLoss: 0.000771\n",
      "Train Epoch: 4 [53760/64795 (83%)]\tLoss: 0.001075\n",
      "Train Epoch: 4 [54400/64795 (84%)]\tLoss: 0.001025\n",
      "Train Epoch: 4 [55040/64795 (85%)]\tLoss: 0.001238\n",
      "Train Epoch: 4 [55680/64795 (86%)]\tLoss: 0.001730\n",
      "Train Epoch: 4 [56320/64795 (87%)]\tLoss: 0.000335\n",
      "Train Epoch: 4 [56960/64795 (88%)]\tLoss: 0.003454\n",
      "Train Epoch: 4 [57600/64795 (89%)]\tLoss: 0.000483\n",
      "Train Epoch: 4 [58240/64795 (90%)]\tLoss: 0.000424\n",
      "Train Epoch: 4 [58880/64795 (91%)]\tLoss: 0.000278\n",
      "Train Epoch: 4 [59520/64795 (92%)]\tLoss: 0.003229\n",
      "Train Epoch: 4 [60160/64795 (93%)]\tLoss: 0.000717\n",
      "Train Epoch: 4 [60800/64795 (94%)]\tLoss: 0.000757\n",
      "Train Epoch: 4 [61440/64795 (95%)]\tLoss: 0.000613\n",
      "Train Epoch: 4 [62080/64795 (96%)]\tLoss: 0.000241\n",
      "Train Epoch: 4 [62720/64795 (97%)]\tLoss: 0.001088\n",
      "Train Epoch: 4 [63360/64795 (98%)]\tLoss: 0.000329\n",
      "Train Epoch: 4 [64000/64795 (99%)]\tLoss: 0.000235\n",
      "Train Epoch: 4 [64640/64795 (100%)]\tLoss: 0.000228\n",
      "Train Epoch: 5 [0/64795 (0%)]\tLoss: 0.000178\n",
      "Train Epoch: 5 [640/64795 (1%)]\tLoss: 0.002187\n",
      "Train Epoch: 5 [1280/64795 (2%)]\tLoss: 0.000535\n",
      "Train Epoch: 5 [1920/64795 (3%)]\tLoss: 0.005784\n",
      "Train Epoch: 5 [2560/64795 (4%)]\tLoss: 0.000886\n",
      "Train Epoch: 5 [3200/64795 (5%)]\tLoss: 0.000478\n",
      "Train Epoch: 5 [3840/64795 (6%)]\tLoss: 0.000514\n",
      "Train Epoch: 5 [4480/64795 (7%)]\tLoss: 0.000387\n",
      "Train Epoch: 5 [5120/64795 (8%)]\tLoss: 0.000259\n",
      "Train Epoch: 5 [5760/64795 (9%)]\tLoss: 0.000435\n",
      "Train Epoch: 5 [6400/64795 (10%)]\tLoss: 0.000175\n",
      "Train Epoch: 5 [7040/64795 (11%)]\tLoss: 0.000540\n",
      "Train Epoch: 5 [7680/64795 (12%)]\tLoss: 0.000853\n",
      "Train Epoch: 5 [8320/64795 (13%)]\tLoss: 0.000190\n",
      "Train Epoch: 5 [8960/64795 (14%)]\tLoss: 0.000173\n",
      "Train Epoch: 5 [9600/64795 (15%)]\tLoss: 0.000286\n",
      "Train Epoch: 5 [10240/64795 (16%)]\tLoss: 0.000350\n",
      "Train Epoch: 5 [10880/64795 (17%)]\tLoss: 0.001315\n",
      "Train Epoch: 5 [11520/64795 (18%)]\tLoss: 0.001035\n",
      "Train Epoch: 5 [12160/64795 (19%)]\tLoss: 0.000317\n",
      "Train Epoch: 5 [12800/64795 (20%)]\tLoss: 0.000316\n",
      "Train Epoch: 5 [13440/64795 (21%)]\tLoss: 0.000355\n",
      "Train Epoch: 5 [14080/64795 (22%)]\tLoss: 0.000273\n",
      "Train Epoch: 5 [14720/64795 (23%)]\tLoss: 0.013463\n",
      "Train Epoch: 5 [15360/64795 (24%)]\tLoss: 0.000212\n",
      "Train Epoch: 5 [16000/64795 (25%)]\tLoss: 0.000711\n",
      "Train Epoch: 5 [16640/64795 (26%)]\tLoss: 0.000418\n",
      "Train Epoch: 5 [17280/64795 (27%)]\tLoss: 0.001815\n",
      "Train Epoch: 5 [17920/64795 (28%)]\tLoss: 0.002161\n",
      "Train Epoch: 5 [18560/64795 (29%)]\tLoss: 0.000370\n",
      "Train Epoch: 5 [19200/64795 (30%)]\tLoss: 0.000875\n",
      "Train Epoch: 5 [19840/64795 (31%)]\tLoss: 0.000857\n",
      "Train Epoch: 5 [20480/64795 (32%)]\tLoss: 0.002900\n",
      "Train Epoch: 5 [21120/64795 (33%)]\tLoss: 0.000278\n",
      "Train Epoch: 5 [21760/64795 (34%)]\tLoss: 0.000229\n",
      "Train Epoch: 5 [22400/64795 (35%)]\tLoss: 0.000987\n",
      "Train Epoch: 5 [23040/64795 (36%)]\tLoss: 0.000771\n",
      "Train Epoch: 5 [23680/64795 (37%)]\tLoss: 0.000734\n",
      "Train Epoch: 5 [24320/64795 (38%)]\tLoss: 0.003288\n",
      "Train Epoch: 5 [24960/64795 (38%)]\tLoss: 0.000602\n",
      "Train Epoch: 5 [25600/64795 (39%)]\tLoss: 0.000202\n",
      "Train Epoch: 5 [26240/64795 (40%)]\tLoss: 0.000303\n",
      "Train Epoch: 5 [26880/64795 (41%)]\tLoss: 0.000565\n",
      "Train Epoch: 5 [27520/64795 (42%)]\tLoss: 0.000228\n",
      "Train Epoch: 5 [28160/64795 (43%)]\tLoss: 0.002985\n",
      "Train Epoch: 5 [28800/64795 (44%)]\tLoss: 0.000571\n",
      "Train Epoch: 5 [29440/64795 (45%)]\tLoss: 0.000440\n",
      "Train Epoch: 5 [30080/64795 (46%)]\tLoss: 0.000888\n",
      "Train Epoch: 5 [30720/64795 (47%)]\tLoss: 0.000804\n",
      "Train Epoch: 5 [31360/64795 (48%)]\tLoss: 0.000309\n",
      "Train Epoch: 5 [32000/64795 (49%)]\tLoss: 0.000704\n",
      "Train Epoch: 5 [32640/64795 (50%)]\tLoss: 0.000796\n",
      "Train Epoch: 5 [33280/64795 (51%)]\tLoss: 0.000791\n",
      "Train Epoch: 5 [33920/64795 (52%)]\tLoss: 0.001409\n",
      "Train Epoch: 5 [34560/64795 (53%)]\tLoss: 0.000420\n",
      "Train Epoch: 5 [35200/64795 (54%)]\tLoss: 0.000830\n",
      "Train Epoch: 5 [35840/64795 (55%)]\tLoss: 0.000129\n",
      "Train Epoch: 5 [36480/64795 (56%)]\tLoss: 0.000254\n",
      "Train Epoch: 5 [37120/64795 (57%)]\tLoss: 0.000131\n",
      "Train Epoch: 5 [37760/64795 (58%)]\tLoss: 0.000696\n",
      "Train Epoch: 5 [38400/64795 (59%)]\tLoss: 0.000592\n",
      "Train Epoch: 5 [39040/64795 (60%)]\tLoss: 0.001610\n",
      "Train Epoch: 5 [39680/64795 (61%)]\tLoss: 0.000945\n",
      "Train Epoch: 5 [40320/64795 (62%)]\tLoss: 0.001943\n",
      "Train Epoch: 5 [40960/64795 (63%)]\tLoss: 0.000912\n",
      "Train Epoch: 5 [41600/64795 (64%)]\tLoss: 0.000284\n",
      "Train Epoch: 5 [42240/64795 (65%)]\tLoss: 0.082337\n",
      "Train Epoch: 5 [42880/64795 (66%)]\tLoss: 0.000358\n",
      "Train Epoch: 5 [43520/64795 (67%)]\tLoss: 0.000993\n",
      "Train Epoch: 5 [44160/64795 (68%)]\tLoss: 0.000438\n",
      "Train Epoch: 5 [44800/64795 (69%)]\tLoss: 0.000333\n",
      "Train Epoch: 5 [45440/64795 (70%)]\tLoss: 0.000519\n",
      "Train Epoch: 5 [46080/64795 (71%)]\tLoss: 0.000823\n",
      "Train Epoch: 5 [46720/64795 (72%)]\tLoss: 0.000501\n",
      "Train Epoch: 5 [47360/64795 (73%)]\tLoss: 0.000248\n",
      "Train Epoch: 5 [48000/64795 (74%)]\tLoss: 0.000193\n",
      "Train Epoch: 5 [48640/64795 (75%)]\tLoss: 0.000236\n",
      "Train Epoch: 5 [49280/64795 (76%)]\tLoss: 0.001495\n",
      "Train Epoch: 5 [49920/64795 (77%)]\tLoss: 0.000811\n",
      "Train Epoch: 5 [50560/64795 (78%)]\tLoss: 0.000304\n",
      "Train Epoch: 5 [51200/64795 (79%)]\tLoss: 0.000187\n",
      "Train Epoch: 5 [51840/64795 (80%)]\tLoss: 0.001350\n",
      "Train Epoch: 5 [52480/64795 (81%)]\tLoss: 0.000433\n",
      "Train Epoch: 5 [53120/64795 (82%)]\tLoss: 0.024503\n",
      "Train Epoch: 5 [53760/64795 (83%)]\tLoss: 0.001240\n",
      "Train Epoch: 5 [54400/64795 (84%)]\tLoss: 0.000280\n",
      "Train Epoch: 5 [55040/64795 (85%)]\tLoss: 0.000476\n",
      "Train Epoch: 5 [55680/64795 (86%)]\tLoss: 0.000719\n",
      "Train Epoch: 5 [56320/64795 (87%)]\tLoss: 0.001230\n",
      "Train Epoch: 5 [56960/64795 (88%)]\tLoss: 0.000602\n",
      "Train Epoch: 5 [57600/64795 (89%)]\tLoss: 0.000618\n",
      "Train Epoch: 5 [58240/64795 (90%)]\tLoss: 0.000396\n",
      "Train Epoch: 5 [58880/64795 (91%)]\tLoss: 0.000238\n",
      "Train Epoch: 5 [59520/64795 (92%)]\tLoss: 0.000278\n",
      "Train Epoch: 5 [60160/64795 (93%)]\tLoss: 0.000273\n",
      "Train Epoch: 5 [60800/64795 (94%)]\tLoss: 0.000419\n",
      "Train Epoch: 5 [61440/64795 (95%)]\tLoss: 0.000289\n",
      "Train Epoch: 5 [62080/64795 (96%)]\tLoss: 0.002410\n",
      "Train Epoch: 5 [62720/64795 (97%)]\tLoss: 0.000478\n",
      "Train Epoch: 5 [63360/64795 (98%)]\tLoss: 0.000666\n",
      "Train Epoch: 5 [64000/64795 (99%)]\tLoss: 0.000650\n",
      "Train Epoch: 5 [64640/64795 (100%)]\tLoss: 0.000255\n",
      "Train Epoch: 6 [0/64795 (0%)]\tLoss: 0.004533\n",
      "Train Epoch: 6 [640/64795 (1%)]\tLoss: 0.000281\n",
      "Train Epoch: 6 [1280/64795 (2%)]\tLoss: 0.001848\n",
      "Train Epoch: 6 [1920/64795 (3%)]\tLoss: 0.000975\n",
      "Train Epoch: 6 [2560/64795 (4%)]\tLoss: 0.002496\n",
      "Train Epoch: 6 [3200/64795 (5%)]\tLoss: 0.000686\n",
      "Train Epoch: 6 [3840/64795 (6%)]\tLoss: 0.000547\n",
      "Train Epoch: 6 [4480/64795 (7%)]\tLoss: 0.000395\n",
      "Train Epoch: 6 [5120/64795 (8%)]\tLoss: 0.000459\n",
      "Train Epoch: 6 [5760/64795 (9%)]\tLoss: 0.002912\n",
      "Train Epoch: 6 [6400/64795 (10%)]\tLoss: 0.001195\n",
      "Train Epoch: 6 [7040/64795 (11%)]\tLoss: 0.000315\n",
      "Train Epoch: 6 [7680/64795 (12%)]\tLoss: 0.000269\n",
      "Train Epoch: 6 [8320/64795 (13%)]\tLoss: 0.000351\n",
      "Train Epoch: 6 [8960/64795 (14%)]\tLoss: 0.000841\n",
      "Train Epoch: 6 [9600/64795 (15%)]\tLoss: 0.000649\n",
      "Train Epoch: 6 [10240/64795 (16%)]\tLoss: 0.000229\n",
      "Train Epoch: 6 [10880/64795 (17%)]\tLoss: 0.082344\n",
      "Train Epoch: 6 [11520/64795 (18%)]\tLoss: 0.000802\n",
      "Train Epoch: 6 [12160/64795 (19%)]\tLoss: 0.001437\n",
      "Train Epoch: 6 [12800/64795 (20%)]\tLoss: 0.000595\n",
      "Train Epoch: 6 [13440/64795 (21%)]\tLoss: 0.000248\n",
      "Train Epoch: 6 [14080/64795 (22%)]\tLoss: 0.001304\n",
      "Train Epoch: 6 [14720/64795 (23%)]\tLoss: 0.003719\n",
      "Train Epoch: 6 [15360/64795 (24%)]\tLoss: 0.000376\n",
      "Train Epoch: 6 [16000/64795 (25%)]\tLoss: 0.001401\n",
      "Train Epoch: 6 [16640/64795 (26%)]\tLoss: 0.000505\n",
      "Train Epoch: 6 [17280/64795 (27%)]\tLoss: 0.000669\n",
      "Train Epoch: 6 [17920/64795 (28%)]\tLoss: 0.000564\n",
      "Train Epoch: 6 [18560/64795 (29%)]\tLoss: 0.001074\n",
      "Train Epoch: 6 [19200/64795 (30%)]\tLoss: 0.000612\n",
      "Train Epoch: 6 [19840/64795 (31%)]\tLoss: 0.000359\n",
      "Train Epoch: 6 [20480/64795 (32%)]\tLoss: 0.000265\n",
      "Train Epoch: 6 [21120/64795 (33%)]\tLoss: 0.000403\n",
      "Train Epoch: 6 [21760/64795 (34%)]\tLoss: 0.000269\n",
      "Train Epoch: 6 [22400/64795 (35%)]\tLoss: 0.000196\n",
      "Train Epoch: 6 [23040/64795 (36%)]\tLoss: 0.000248\n",
      "Train Epoch: 6 [23680/64795 (37%)]\tLoss: 0.000259\n",
      "Train Epoch: 6 [24320/64795 (38%)]\tLoss: 0.000176\n",
      "Train Epoch: 6 [24960/64795 (38%)]\tLoss: 0.001842\n",
      "Train Epoch: 6 [25600/64795 (39%)]\tLoss: 0.000889\n",
      "Train Epoch: 6 [26240/64795 (40%)]\tLoss: 0.001122\n",
      "Train Epoch: 6 [26880/64795 (41%)]\tLoss: 0.000265\n",
      "Train Epoch: 6 [27520/64795 (42%)]\tLoss: 0.000116\n",
      "Train Epoch: 6 [28160/64795 (43%)]\tLoss: 0.000127\n",
      "Train Epoch: 6 [28800/64795 (44%)]\tLoss: 0.000184\n",
      "Train Epoch: 6 [29440/64795 (45%)]\tLoss: 0.000222\n",
      "Train Epoch: 6 [30080/64795 (46%)]\tLoss: 0.000190\n",
      "Train Epoch: 6 [30720/64795 (47%)]\tLoss: 0.000175\n",
      "Train Epoch: 6 [31360/64795 (48%)]\tLoss: 0.000456\n",
      "Train Epoch: 6 [32000/64795 (49%)]\tLoss: 0.002235\n",
      "Train Epoch: 6 [32640/64795 (50%)]\tLoss: 0.000294\n",
      "Train Epoch: 6 [33280/64795 (51%)]\tLoss: 0.000251\n",
      "Train Epoch: 6 [33920/64795 (52%)]\tLoss: 0.000248\n",
      "Train Epoch: 6 [34560/64795 (53%)]\tLoss: 0.001340\n",
      "Train Epoch: 6 [35200/64795 (54%)]\tLoss: 0.000686\n",
      "Train Epoch: 6 [35840/64795 (55%)]\tLoss: 0.000243\n",
      "Train Epoch: 6 [36480/64795 (56%)]\tLoss: 0.000138\n",
      "Train Epoch: 6 [37120/64795 (57%)]\tLoss: 0.000339\n",
      "Train Epoch: 6 [37760/64795 (58%)]\tLoss: 0.000135\n",
      "Train Epoch: 6 [38400/64795 (59%)]\tLoss: 0.000148\n",
      "Train Epoch: 6 [39040/64795 (60%)]\tLoss: 0.030854\n",
      "Train Epoch: 6 [39680/64795 (61%)]\tLoss: 0.000674\n",
      "Train Epoch: 6 [40320/64795 (62%)]\tLoss: 0.000658\n",
      "Train Epoch: 6 [40960/64795 (63%)]\tLoss: 0.000555\n",
      "Train Epoch: 6 [41600/64795 (64%)]\tLoss: 0.000357\n",
      "Train Epoch: 6 [42240/64795 (65%)]\tLoss: 0.000116\n",
      "Train Epoch: 6 [42880/64795 (66%)]\tLoss: 0.000119\n",
      "Train Epoch: 6 [43520/64795 (67%)]\tLoss: 0.000651\n",
      "Train Epoch: 6 [44160/64795 (68%)]\tLoss: 0.001135\n",
      "Train Epoch: 6 [44800/64795 (69%)]\tLoss: 0.000928\n",
      "Train Epoch: 6 [45440/64795 (70%)]\tLoss: 0.012660\n",
      "Train Epoch: 6 [46080/64795 (71%)]\tLoss: 0.000854\n",
      "Train Epoch: 6 [46720/64795 (72%)]\tLoss: 0.001672\n",
      "Train Epoch: 6 [47360/64795 (73%)]\tLoss: 0.000812\n",
      "Train Epoch: 6 [48000/64795 (74%)]\tLoss: 0.000446\n",
      "Train Epoch: 6 [48640/64795 (75%)]\tLoss: 0.001869\n",
      "Train Epoch: 6 [49280/64795 (76%)]\tLoss: 0.000442\n",
      "Train Epoch: 6 [49920/64795 (77%)]\tLoss: 0.000964\n",
      "Train Epoch: 6 [50560/64795 (78%)]\tLoss: 0.000523\n",
      "Train Epoch: 6 [51200/64795 (79%)]\tLoss: 0.000282\n",
      "Train Epoch: 6 [51840/64795 (80%)]\tLoss: 0.000310\n",
      "Train Epoch: 6 [52480/64795 (81%)]\tLoss: 0.026275\n",
      "Train Epoch: 6 [53120/64795 (82%)]\tLoss: 0.000861\n",
      "Train Epoch: 6 [53760/64795 (83%)]\tLoss: 0.000841\n",
      "Train Epoch: 6 [54400/64795 (84%)]\tLoss: 0.000446\n",
      "Train Epoch: 6 [55040/64795 (85%)]\tLoss: 0.000480\n",
      "Train Epoch: 6 [55680/64795 (86%)]\tLoss: 0.024654\n",
      "Train Epoch: 6 [56320/64795 (87%)]\tLoss: 0.000774\n",
      "Train Epoch: 6 [56960/64795 (88%)]\tLoss: 0.000560\n",
      "Train Epoch: 6 [57600/64795 (89%)]\tLoss: 0.000177\n",
      "Train Epoch: 6 [58240/64795 (90%)]\tLoss: 0.000400\n",
      "Train Epoch: 6 [58880/64795 (91%)]\tLoss: 0.000436\n",
      "Train Epoch: 6 [59520/64795 (92%)]\tLoss: 0.000708\n",
      "Train Epoch: 6 [60160/64795 (93%)]\tLoss: 0.000428\n",
      "Train Epoch: 6 [60800/64795 (94%)]\tLoss: 0.001587\n",
      "Train Epoch: 6 [61440/64795 (95%)]\tLoss: 0.000528\n",
      "Train Epoch: 6 [62080/64795 (96%)]\tLoss: 0.000563\n",
      "Train Epoch: 6 [62720/64795 (97%)]\tLoss: 0.000853\n",
      "Train Epoch: 6 [63360/64795 (98%)]\tLoss: 0.000996\n",
      "Train Epoch: 6 [64000/64795 (99%)]\tLoss: 0.000426\n",
      "Train Epoch: 6 [64640/64795 (100%)]\tLoss: 0.000363\n",
      "Train Epoch: 7 [0/64795 (0%)]\tLoss: 0.000182\n",
      "Train Epoch: 7 [640/64795 (1%)]\tLoss: 0.000414\n",
      "Train Epoch: 7 [1280/64795 (2%)]\tLoss: 0.000483\n",
      "Train Epoch: 7 [1920/64795 (3%)]\tLoss: 0.000381\n",
      "Train Epoch: 7 [2560/64795 (4%)]\tLoss: 0.000879\n",
      "Train Epoch: 7 [3200/64795 (5%)]\tLoss: 0.000430\n",
      "Train Epoch: 7 [3840/64795 (6%)]\tLoss: 0.000252\n",
      "Train Epoch: 7 [4480/64795 (7%)]\tLoss: 0.000256\n",
      "Train Epoch: 7 [5120/64795 (8%)]\tLoss: 0.000622\n",
      "Train Epoch: 7 [5760/64795 (9%)]\tLoss: 0.000775\n",
      "Train Epoch: 7 [6400/64795 (10%)]\tLoss: 0.000422\n",
      "Train Epoch: 7 [7040/64795 (11%)]\tLoss: 0.001340\n",
      "Train Epoch: 7 [7680/64795 (12%)]\tLoss: 0.000108\n",
      "Train Epoch: 7 [8320/64795 (13%)]\tLoss: 0.000130\n",
      "Train Epoch: 7 [8960/64795 (14%)]\tLoss: 0.000284\n",
      "Train Epoch: 7 [9600/64795 (15%)]\tLoss: 0.000191\n",
      "Train Epoch: 7 [10240/64795 (16%)]\tLoss: 0.000224\n",
      "Train Epoch: 7 [10880/64795 (17%)]\tLoss: 0.000268\n",
      "Train Epoch: 7 [11520/64795 (18%)]\tLoss: 0.000337\n",
      "Train Epoch: 7 [12160/64795 (19%)]\tLoss: 0.000176\n",
      "Train Epoch: 7 [12800/64795 (20%)]\tLoss: 0.000285\n",
      "Train Epoch: 7 [13440/64795 (21%)]\tLoss: 0.002633\n",
      "Train Epoch: 7 [14080/64795 (22%)]\tLoss: 0.000224\n",
      "Train Epoch: 7 [14720/64795 (23%)]\tLoss: 0.000664\n",
      "Train Epoch: 7 [15360/64795 (24%)]\tLoss: 0.000241\n",
      "Train Epoch: 7 [16000/64795 (25%)]\tLoss: 0.000283\n",
      "Train Epoch: 7 [16640/64795 (26%)]\tLoss: 0.000501\n",
      "Train Epoch: 7 [17280/64795 (27%)]\tLoss: 0.000578\n",
      "Train Epoch: 7 [17920/64795 (28%)]\tLoss: 0.000481\n",
      "Train Epoch: 7 [18560/64795 (29%)]\tLoss: 0.000571\n",
      "Train Epoch: 7 [19200/64795 (30%)]\tLoss: 0.000346\n",
      "Train Epoch: 7 [19840/64795 (31%)]\tLoss: 0.000197\n",
      "Train Epoch: 7 [20480/64795 (32%)]\tLoss: 0.000202\n",
      "Train Epoch: 7 [21120/64795 (33%)]\tLoss: 0.000162\n",
      "Train Epoch: 7 [21760/64795 (34%)]\tLoss: 0.021223\n",
      "Train Epoch: 7 [22400/64795 (35%)]\tLoss: 0.000264\n",
      "Train Epoch: 7 [23040/64795 (36%)]\tLoss: 0.000229\n",
      "Train Epoch: 7 [23680/64795 (37%)]\tLoss: 0.000128\n",
      "Train Epoch: 7 [24320/64795 (38%)]\tLoss: 0.000357\n",
      "Train Epoch: 7 [24960/64795 (38%)]\tLoss: 0.000287\n",
      "Train Epoch: 7 [25600/64795 (39%)]\tLoss: 0.001541\n",
      "Train Epoch: 7 [26240/64795 (40%)]\tLoss: 0.001371\n",
      "Train Epoch: 7 [26880/64795 (41%)]\tLoss: 0.000736\n",
      "Train Epoch: 7 [27520/64795 (42%)]\tLoss: 0.000306\n",
      "Train Epoch: 7 [28160/64795 (43%)]\tLoss: 0.022533\n",
      "Train Epoch: 7 [28800/64795 (44%)]\tLoss: 0.000308\n",
      "Train Epoch: 7 [29440/64795 (45%)]\tLoss: 0.000822\n",
      "Train Epoch: 7 [30080/64795 (46%)]\tLoss: 0.000241\n",
      "Train Epoch: 7 [30720/64795 (47%)]\tLoss: 0.000117\n",
      "Train Epoch: 7 [31360/64795 (48%)]\tLoss: 0.000227\n",
      "Train Epoch: 7 [32000/64795 (49%)]\tLoss: 0.003294\n",
      "Train Epoch: 7 [32640/64795 (50%)]\tLoss: 0.001805\n",
      "Train Epoch: 7 [33280/64795 (51%)]\tLoss: 0.000405\n",
      "Train Epoch: 7 [33920/64795 (52%)]\tLoss: 0.000524\n",
      "Train Epoch: 7 [34560/64795 (53%)]\tLoss: 0.010205\n",
      "Train Epoch: 7 [35200/64795 (54%)]\tLoss: 0.000652\n",
      "Train Epoch: 7 [35840/64795 (55%)]\tLoss: 0.001717\n",
      "Train Epoch: 7 [36480/64795 (56%)]\tLoss: 0.000437\n",
      "Train Epoch: 7 [37120/64795 (57%)]\tLoss: 0.000416\n",
      "Train Epoch: 7 [37760/64795 (58%)]\tLoss: 0.000598\n",
      "Train Epoch: 7 [38400/64795 (59%)]\tLoss: 0.000300\n",
      "Train Epoch: 7 [39040/64795 (60%)]\tLoss: 0.000476\n",
      "Train Epoch: 7 [39680/64795 (61%)]\tLoss: 0.000214\n",
      "Train Epoch: 7 [40320/64795 (62%)]\tLoss: 0.000505\n",
      "Train Epoch: 7 [40960/64795 (63%)]\tLoss: 0.000220\n",
      "Train Epoch: 7 [41600/64795 (64%)]\tLoss: 0.000423\n",
      "Train Epoch: 7 [42240/64795 (65%)]\tLoss: 0.000147\n",
      "Train Epoch: 7 [42880/64795 (66%)]\tLoss: 0.005410\n",
      "Train Epoch: 7 [43520/64795 (67%)]\tLoss: 0.000771\n",
      "Train Epoch: 7 [44160/64795 (68%)]\tLoss: 0.000299\n",
      "Train Epoch: 7 [44800/64795 (69%)]\tLoss: 0.000826\n",
      "Train Epoch: 7 [45440/64795 (70%)]\tLoss: 0.000274\n",
      "Train Epoch: 7 [46080/64795 (71%)]\tLoss: 0.000219\n",
      "Train Epoch: 7 [46720/64795 (72%)]\tLoss: 0.001281\n",
      "Train Epoch: 7 [47360/64795 (73%)]\tLoss: 0.001716\n",
      "Train Epoch: 7 [48000/64795 (74%)]\tLoss: 0.000571\n",
      "Train Epoch: 7 [48640/64795 (75%)]\tLoss: 0.000476\n",
      "Train Epoch: 7 [49280/64795 (76%)]\tLoss: 0.000329\n",
      "Train Epoch: 7 [49920/64795 (77%)]\tLoss: 0.000441\n",
      "Train Epoch: 7 [50560/64795 (78%)]\tLoss: 0.000149\n",
      "Train Epoch: 7 [51200/64795 (79%)]\tLoss: 0.000160\n",
      "Train Epoch: 7 [51840/64795 (80%)]\tLoss: 0.000127\n",
      "Train Epoch: 7 [52480/64795 (81%)]\tLoss: 0.001264\n",
      "Train Epoch: 7 [53120/64795 (82%)]\tLoss: 0.000825\n",
      "Train Epoch: 7 [53760/64795 (83%)]\tLoss: 0.000413\n",
      "Train Epoch: 7 [54400/64795 (84%)]\tLoss: 0.000996\n",
      "Train Epoch: 7 [55040/64795 (85%)]\tLoss: 0.000749\n",
      "Train Epoch: 7 [55680/64795 (86%)]\tLoss: 0.000301\n",
      "Train Epoch: 7 [56320/64795 (87%)]\tLoss: 0.000254\n",
      "Train Epoch: 7 [56960/64795 (88%)]\tLoss: 0.001042\n",
      "Train Epoch: 7 [57600/64795 (89%)]\tLoss: 0.001423\n",
      "Train Epoch: 7 [58240/64795 (90%)]\tLoss: 0.000505\n",
      "Train Epoch: 7 [58880/64795 (91%)]\tLoss: 0.000742\n",
      "Train Epoch: 7 [59520/64795 (92%)]\tLoss: 0.000233\n",
      "Train Epoch: 7 [60160/64795 (93%)]\tLoss: 0.000170\n",
      "Train Epoch: 7 [60800/64795 (94%)]\tLoss: 0.006917\n",
      "Train Epoch: 7 [61440/64795 (95%)]\tLoss: 0.043314\n",
      "Train Epoch: 7 [62080/64795 (96%)]\tLoss: 0.000402\n",
      "Train Epoch: 7 [62720/64795 (97%)]\tLoss: 0.000519\n",
      "Train Epoch: 7 [63360/64795 (98%)]\tLoss: 0.001007\n",
      "Train Epoch: 7 [64000/64795 (99%)]\tLoss: 0.000130\n",
      "Train Epoch: 7 [64640/64795 (100%)]\tLoss: 0.000481\n",
      "Train Epoch: 8 [0/64795 (0%)]\tLoss: 0.000874\n",
      "Train Epoch: 8 [640/64795 (1%)]\tLoss: 0.000271\n",
      "Train Epoch: 8 [1280/64795 (2%)]\tLoss: 0.000335\n",
      "Train Epoch: 8 [1920/64795 (3%)]\tLoss: 0.000130\n",
      "Train Epoch: 8 [2560/64795 (4%)]\tLoss: 0.000437\n",
      "Train Epoch: 8 [3200/64795 (5%)]\tLoss: 0.000534\n",
      "Train Epoch: 8 [3840/64795 (6%)]\tLoss: 0.001521\n",
      "Train Epoch: 8 [4480/64795 (7%)]\tLoss: 0.000630\n",
      "Train Epoch: 8 [5120/64795 (8%)]\tLoss: 0.000333\n",
      "Train Epoch: 8 [5760/64795 (9%)]\tLoss: 0.000664\n",
      "Train Epoch: 8 [6400/64795 (10%)]\tLoss: 0.000204\n",
      "Train Epoch: 8 [7040/64795 (11%)]\tLoss: 0.003921\n",
      "Train Epoch: 8 [7680/64795 (12%)]\tLoss: 0.000251\n",
      "Train Epoch: 8 [8320/64795 (13%)]\tLoss: 0.000710\n",
      "Train Epoch: 8 [8960/64795 (14%)]\tLoss: 0.000393\n",
      "Train Epoch: 8 [9600/64795 (15%)]\tLoss: 0.000164\n",
      "Train Epoch: 8 [10240/64795 (16%)]\tLoss: 0.000702\n",
      "Train Epoch: 8 [10880/64795 (17%)]\tLoss: 0.000245\n",
      "Train Epoch: 8 [11520/64795 (18%)]\tLoss: 0.000582\n",
      "Train Epoch: 8 [12160/64795 (19%)]\tLoss: 0.000639\n",
      "Train Epoch: 8 [12800/64795 (20%)]\tLoss: 0.001217\n",
      "Train Epoch: 8 [13440/64795 (21%)]\tLoss: 0.001503\n",
      "Train Epoch: 8 [14080/64795 (22%)]\tLoss: 0.000700\n",
      "Train Epoch: 8 [14720/64795 (23%)]\tLoss: 0.000373\n",
      "Train Epoch: 8 [15360/64795 (24%)]\tLoss: 0.000239\n",
      "Train Epoch: 8 [16000/64795 (25%)]\tLoss: 0.000104\n",
      "Train Epoch: 8 [16640/64795 (26%)]\tLoss: 0.000188\n",
      "Train Epoch: 8 [17280/64795 (27%)]\tLoss: 0.000990\n",
      "Train Epoch: 8 [17920/64795 (28%)]\tLoss: 0.000462\n",
      "Train Epoch: 8 [18560/64795 (29%)]\tLoss: 0.000178\n",
      "Train Epoch: 8 [19200/64795 (30%)]\tLoss: 0.000220\n",
      "Train Epoch: 8 [19840/64795 (31%)]\tLoss: 0.000858\n",
      "Train Epoch: 8 [20480/64795 (32%)]\tLoss: 0.000425\n",
      "Train Epoch: 8 [21120/64795 (33%)]\tLoss: 0.000498\n",
      "Train Epoch: 8 [21760/64795 (34%)]\tLoss: 0.000662\n",
      "Train Epoch: 8 [22400/64795 (35%)]\tLoss: 0.002566\n",
      "Train Epoch: 8 [23040/64795 (36%)]\tLoss: 0.000506\n",
      "Train Epoch: 8 [23680/64795 (37%)]\tLoss: 0.000420\n",
      "Train Epoch: 8 [24320/64795 (38%)]\tLoss: 0.000372\n",
      "Train Epoch: 8 [24960/64795 (38%)]\tLoss: 0.000216\n",
      "Train Epoch: 8 [25600/64795 (39%)]\tLoss: 0.000175\n",
      "Train Epoch: 8 [26240/64795 (40%)]\tLoss: 0.000944\n",
      "Train Epoch: 8 [26880/64795 (41%)]\tLoss: 0.000376\n",
      "Train Epoch: 8 [27520/64795 (42%)]\tLoss: 0.000203\n",
      "Train Epoch: 8 [28160/64795 (43%)]\tLoss: 0.000608\n",
      "Train Epoch: 8 [28800/64795 (44%)]\tLoss: 0.000252\n",
      "Train Epoch: 8 [29440/64795 (45%)]\tLoss: 0.000448\n",
      "Train Epoch: 8 [30080/64795 (46%)]\tLoss: 0.000411\n",
      "Train Epoch: 8 [30720/64795 (47%)]\tLoss: 0.000347\n",
      "Train Epoch: 8 [31360/64795 (48%)]\tLoss: 0.038997\n",
      "Train Epoch: 8 [32000/64795 (49%)]\tLoss: 0.000455\n",
      "Train Epoch: 8 [32640/64795 (50%)]\tLoss: 0.000253\n",
      "Train Epoch: 8 [33280/64795 (51%)]\tLoss: 0.000207\n",
      "Train Epoch: 8 [33920/64795 (52%)]\tLoss: 0.000311\n",
      "Train Epoch: 8 [34560/64795 (53%)]\tLoss: 0.000313\n",
      "Train Epoch: 8 [35200/64795 (54%)]\tLoss: 0.000768\n",
      "Train Epoch: 8 [35840/64795 (55%)]\tLoss: 0.000745\n",
      "Train Epoch: 8 [36480/64795 (56%)]\tLoss: 0.001889\n",
      "Train Epoch: 8 [37120/64795 (57%)]\tLoss: 0.000793\n",
      "Train Epoch: 8 [37760/64795 (58%)]\tLoss: 0.000476\n",
      "Train Epoch: 8 [38400/64795 (59%)]\tLoss: 0.000332\n",
      "Train Epoch: 8 [39040/64795 (60%)]\tLoss: 0.000572\n",
      "Train Epoch: 8 [39680/64795 (61%)]\tLoss: 0.000142\n",
      "Train Epoch: 8 [40320/64795 (62%)]\tLoss: 0.000282\n",
      "Train Epoch: 8 [40960/64795 (63%)]\tLoss: 0.000601\n",
      "Train Epoch: 8 [41600/64795 (64%)]\tLoss: 0.000161\n",
      "Train Epoch: 8 [42240/64795 (65%)]\tLoss: 0.000284\n",
      "Train Epoch: 8 [42880/64795 (66%)]\tLoss: 0.000758\n",
      "Train Epoch: 8 [43520/64795 (67%)]\tLoss: 0.000281\n",
      "Train Epoch: 8 [44160/64795 (68%)]\tLoss: 0.000299\n",
      "Train Epoch: 8 [44800/64795 (69%)]\tLoss: 0.000214\n",
      "Train Epoch: 8 [45440/64795 (70%)]\tLoss: 0.000207\n",
      "Train Epoch: 8 [46080/64795 (71%)]\tLoss: 0.000211\n",
      "Train Epoch: 8 [46720/64795 (72%)]\tLoss: 0.000117\n",
      "Train Epoch: 8 [47360/64795 (73%)]\tLoss: 0.000169\n",
      "Train Epoch: 8 [48000/64795 (74%)]\tLoss: 0.000066\n",
      "Train Epoch: 8 [48640/64795 (75%)]\tLoss: 0.000241\n",
      "Train Epoch: 8 [49280/64795 (76%)]\tLoss: 0.000573\n",
      "Train Epoch: 8 [49920/64795 (77%)]\tLoss: 0.000354\n",
      "Train Epoch: 8 [50560/64795 (78%)]\tLoss: 0.000160\n",
      "Train Epoch: 8 [51200/64795 (79%)]\tLoss: 0.000201\n",
      "Train Epoch: 8 [51840/64795 (80%)]\tLoss: 0.000266\n",
      "Train Epoch: 8 [52480/64795 (81%)]\tLoss: 0.000319\n",
      "Train Epoch: 8 [53120/64795 (82%)]\tLoss: 0.000514\n",
      "Train Epoch: 8 [53760/64795 (83%)]\tLoss: 0.000424\n",
      "Train Epoch: 8 [54400/64795 (84%)]\tLoss: 0.000320\n",
      "Train Epoch: 8 [55040/64795 (85%)]\tLoss: 0.000705\n",
      "Train Epoch: 8 [55680/64795 (86%)]\tLoss: 0.000126\n",
      "Train Epoch: 8 [56320/64795 (87%)]\tLoss: 0.000263\n",
      "Train Epoch: 8 [56960/64795 (88%)]\tLoss: 0.001584\n",
      "Train Epoch: 8 [57600/64795 (89%)]\tLoss: 0.000359\n",
      "Train Epoch: 8 [58240/64795 (90%)]\tLoss: 0.000176\n",
      "Train Epoch: 8 [58880/64795 (91%)]\tLoss: 0.003819\n",
      "Train Epoch: 8 [59520/64795 (92%)]\tLoss: 0.000648\n",
      "Train Epoch: 8 [60160/64795 (93%)]\tLoss: 0.000429\n",
      "Train Epoch: 8 [60800/64795 (94%)]\tLoss: 0.000257\n",
      "Train Epoch: 8 [61440/64795 (95%)]\tLoss: 0.000461\n",
      "Train Epoch: 8 [62080/64795 (96%)]\tLoss: 0.000304\n",
      "Train Epoch: 8 [62720/64795 (97%)]\tLoss: 0.000161\n",
      "Train Epoch: 8 [63360/64795 (98%)]\tLoss: 0.000257\n",
      "Train Epoch: 8 [64000/64795 (99%)]\tLoss: 0.000506\n",
      "Train Epoch: 8 [64640/64795 (100%)]\tLoss: 0.000492\n",
      "Train Epoch: 9 [0/64795 (0%)]\tLoss: 0.000236\n",
      "Train Epoch: 9 [640/64795 (1%)]\tLoss: 0.000872\n",
      "Train Epoch: 9 [1280/64795 (2%)]\tLoss: 0.000282\n",
      "Train Epoch: 9 [1920/64795 (3%)]\tLoss: 0.000182\n",
      "Train Epoch: 9 [2560/64795 (4%)]\tLoss: 0.000118\n",
      "Train Epoch: 9 [3200/64795 (5%)]\tLoss: 0.000191\n",
      "Train Epoch: 9 [3840/64795 (6%)]\tLoss: 0.000790\n",
      "Train Epoch: 9 [4480/64795 (7%)]\tLoss: 0.001222\n",
      "Train Epoch: 9 [5120/64795 (8%)]\tLoss: 0.000501\n",
      "Train Epoch: 9 [5760/64795 (9%)]\tLoss: 0.001492\n",
      "Train Epoch: 9 [6400/64795 (10%)]\tLoss: 0.000804\n",
      "Train Epoch: 9 [7040/64795 (11%)]\tLoss: 0.003256\n",
      "Train Epoch: 9 [7680/64795 (12%)]\tLoss: 0.001107\n",
      "Train Epoch: 9 [8320/64795 (13%)]\tLoss: 0.000921\n",
      "Train Epoch: 9 [8960/64795 (14%)]\tLoss: 0.000804\n",
      "Train Epoch: 9 [9600/64795 (15%)]\tLoss: 0.000269\n",
      "Train Epoch: 9 [10240/64795 (16%)]\tLoss: 0.000293\n",
      "Train Epoch: 9 [10880/64795 (17%)]\tLoss: 0.000518\n",
      "Train Epoch: 9 [11520/64795 (18%)]\tLoss: 0.001413\n",
      "Train Epoch: 9 [12160/64795 (19%)]\tLoss: 0.000888\n",
      "Train Epoch: 9 [12800/64795 (20%)]\tLoss: 0.005719\n",
      "Train Epoch: 9 [13440/64795 (21%)]\tLoss: 0.000499\n",
      "Train Epoch: 9 [14080/64795 (22%)]\tLoss: 0.000173\n",
      "Train Epoch: 9 [14720/64795 (23%)]\tLoss: 0.000154\n",
      "Train Epoch: 9 [15360/64795 (24%)]\tLoss: 0.000094\n",
      "Train Epoch: 9 [16000/64795 (25%)]\tLoss: 0.004034\n",
      "Train Epoch: 9 [16640/64795 (26%)]\tLoss: 0.000151\n",
      "Train Epoch: 9 [17280/64795 (27%)]\tLoss: 0.000544\n",
      "Train Epoch: 9 [17920/64795 (28%)]\tLoss: 0.000638\n",
      "Train Epoch: 9 [18560/64795 (29%)]\tLoss: 0.000073\n",
      "Train Epoch: 9 [19200/64795 (30%)]\tLoss: 0.000862\n",
      "Train Epoch: 9 [19840/64795 (31%)]\tLoss: 0.000251\n",
      "Train Epoch: 9 [20480/64795 (32%)]\tLoss: 0.003023\n",
      "Train Epoch: 9 [21120/64795 (33%)]\tLoss: 0.000222\n",
      "Train Epoch: 9 [21760/64795 (34%)]\tLoss: 0.025707\n",
      "Train Epoch: 9 [22400/64795 (35%)]\tLoss: 0.000524\n",
      "Train Epoch: 9 [23040/64795 (36%)]\tLoss: 0.000635\n",
      "Train Epoch: 9 [23680/64795 (37%)]\tLoss: 0.001032\n",
      "Train Epoch: 9 [24320/64795 (38%)]\tLoss: 0.000774\n",
      "Train Epoch: 9 [24960/64795 (38%)]\tLoss: 0.000284\n",
      "Train Epoch: 9 [25600/64795 (39%)]\tLoss: 0.000086\n",
      "Train Epoch: 9 [26240/64795 (40%)]\tLoss: 0.002050\n",
      "Train Epoch: 9 [26880/64795 (41%)]\tLoss: 0.001332\n",
      "Train Epoch: 9 [27520/64795 (42%)]\tLoss: 0.001276\n",
      "Train Epoch: 9 [28160/64795 (43%)]\tLoss: 0.001094\n",
      "Train Epoch: 9 [28800/64795 (44%)]\tLoss: 0.000141\n",
      "Train Epoch: 9 [29440/64795 (45%)]\tLoss: 0.000293\n",
      "Train Epoch: 9 [30080/64795 (46%)]\tLoss: 0.000188\n",
      "Train Epoch: 9 [30720/64795 (47%)]\tLoss: 0.000222\n",
      "Train Epoch: 9 [31360/64795 (48%)]\tLoss: 0.000212\n",
      "Train Epoch: 9 [32000/64795 (49%)]\tLoss: 0.000299\n",
      "Train Epoch: 9 [32640/64795 (50%)]\tLoss: 0.001242\n",
      "Train Epoch: 9 [33280/64795 (51%)]\tLoss: 0.000238\n",
      "Train Epoch: 9 [33920/64795 (52%)]\tLoss: 0.000364\n",
      "Train Epoch: 9 [34560/64795 (53%)]\tLoss: 0.000147\n",
      "Train Epoch: 9 [35200/64795 (54%)]\tLoss: 0.000513\n",
      "Train Epoch: 9 [35840/64795 (55%)]\tLoss: 0.000124\n",
      "Train Epoch: 9 [36480/64795 (56%)]\tLoss: 0.000188\n",
      "Train Epoch: 9 [37120/64795 (57%)]\tLoss: 0.000146\n",
      "Train Epoch: 9 [37760/64795 (58%)]\tLoss: 0.000080\n",
      "Train Epoch: 9 [38400/64795 (59%)]\tLoss: 0.000139\n",
      "Train Epoch: 9 [39040/64795 (60%)]\tLoss: 0.000121\n",
      "Train Epoch: 9 [39680/64795 (61%)]\tLoss: 0.000467\n",
      "Train Epoch: 9 [40320/64795 (62%)]\tLoss: 0.000311\n",
      "Train Epoch: 9 [40960/64795 (63%)]\tLoss: 0.000423\n",
      "Train Epoch: 9 [41600/64795 (64%)]\tLoss: 0.000120\n",
      "Train Epoch: 9 [42240/64795 (65%)]\tLoss: 0.000077\n",
      "Train Epoch: 9 [42880/64795 (66%)]\tLoss: 0.000084\n",
      "Train Epoch: 9 [43520/64795 (67%)]\tLoss: 0.000048\n",
      "Train Epoch: 9 [44160/64795 (68%)]\tLoss: 0.000069\n",
      "Train Epoch: 9 [44800/64795 (69%)]\tLoss: 0.000094\n",
      "Train Epoch: 9 [45440/64795 (70%)]\tLoss: 0.000137\n",
      "Train Epoch: 9 [46080/64795 (71%)]\tLoss: 0.000043\n",
      "Train Epoch: 9 [46720/64795 (72%)]\tLoss: 0.000067\n",
      "Train Epoch: 9 [47360/64795 (73%)]\tLoss: 0.041238\n",
      "Train Epoch: 9 [48000/64795 (74%)]\tLoss: 0.006870\n",
      "Train Epoch: 9 [48640/64795 (75%)]\tLoss: 0.001249\n",
      "Train Epoch: 9 [49280/64795 (76%)]\tLoss: 0.001368\n",
      "Train Epoch: 9 [49920/64795 (77%)]\tLoss: 0.000647\n",
      "Train Epoch: 9 [50560/64795 (78%)]\tLoss: 0.000572\n",
      "Train Epoch: 9 [51200/64795 (79%)]\tLoss: 0.000118\n",
      "Train Epoch: 9 [51840/64795 (80%)]\tLoss: 0.000199\n",
      "Train Epoch: 9 [52480/64795 (81%)]\tLoss: 0.000324\n",
      "Train Epoch: 9 [53120/64795 (82%)]\tLoss: 0.012787\n",
      "Train Epoch: 9 [53760/64795 (83%)]\tLoss: 0.000570\n",
      "Train Epoch: 9 [54400/64795 (84%)]\tLoss: 0.000968\n",
      "Train Epoch: 9 [55040/64795 (85%)]\tLoss: 0.000238\n",
      "Train Epoch: 9 [55680/64795 (86%)]\tLoss: 0.000427\n",
      "Train Epoch: 9 [56320/64795 (87%)]\tLoss: 0.000541\n",
      "Train Epoch: 9 [56960/64795 (88%)]\tLoss: 0.000530\n",
      "Train Epoch: 9 [57600/64795 (89%)]\tLoss: 0.000347\n",
      "Train Epoch: 9 [58240/64795 (90%)]\tLoss: 0.000536\n",
      "Train Epoch: 9 [58880/64795 (91%)]\tLoss: 0.071403\n",
      "Train Epoch: 9 [59520/64795 (92%)]\tLoss: 0.000985\n",
      "Train Epoch: 9 [60160/64795 (93%)]\tLoss: 0.000214\n",
      "Train Epoch: 9 [60800/64795 (94%)]\tLoss: 0.000314\n",
      "Train Epoch: 9 [61440/64795 (95%)]\tLoss: 0.000167\n",
      "Train Epoch: 9 [62080/64795 (96%)]\tLoss: 0.000565\n",
      "Train Epoch: 9 [62720/64795 (97%)]\tLoss: 0.000508\n",
      "Train Epoch: 9 [63360/64795 (98%)]\tLoss: 0.000340\n",
      "Train Epoch: 9 [64000/64795 (99%)]\tLoss: 0.000287\n",
      "Train Epoch: 9 [64640/64795 (100%)]\tLoss: 0.001601\n"
     ]
    }
   ],
   "source": [
    "if __name__ =='__main__':\n",
    "    can_image = np.load(\"../data/dcgan/gear_image_data.npy\")\n",
    "    can_image_label = np.load('../data/dcgan/gear_image_label.npy')\n",
    "    features = torch.tensor(can_image, dtype=torch.float32)\n",
    "\n",
    "    features = features.reshape(-1,1,48,48)\n",
    "    labels = torch.tensor(can_image_label, dtype=torch.float32)  # MSELoss -> torch.float32\n",
    "    train_data, test_data, train_label, test_label = train_test_split(features, labels, random_state=1, train_size=0.7,\n",
    "                                                                      test_size=0.3, stratify=labels)\n",
    "    train_ids = TensorDataset(train_data, train_label)\n",
    "    train_loader = DataLoader(dataset=train_ids, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    ###################################################################################first discriminator train & get normal data for GAN trainning\n",
    "    train(netD,train_loader,10,optimizerD,criterion)\n",
    "    torch.save(netD, '../model/GIDS_DCGAN_KnownAttack_gear.pkl')\n",
    "    netD = torch.load('../model/GIDS_DCGAN_KnownAttack_gear.pkl')\n",
    "    netD.to('cpu')\n",
    "    # normal_dataset = get_normal_data(netD,features,0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_dataset = get_normal_data(netD,features,0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of the first discriminator for gear attack\n",
      "DoS attack\n"
     ]
    }
   ],
   "source": [
    "###################################################################################test for first discriminator\n",
    "print('result of the first discriminator for gear attack')\n",
    "print('DoS attack')    \n",
    "can_image = np.load(\"../data/dcgan/DoS_image_data.npy\")\n",
    "can_image_label = np.load('../data/dcgan/DoS_image_label.npy')\n",
    "features = torch.tensor(can_image, dtype=torch.float32)\n",
    "features = features.reshape(-1, 1, 48, 48)\n",
    "labels = torch.tensor(can_image_label, dtype=torch.float32)  #MSELoss -> torch.float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution_calculate(netD, features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_p(netD, features, labels, 0.5)\n",
    "print('Fuzzy attack')\n",
    "can_image = np.load(\"../data/dcgan/Fuzzy_image_data.npy\")\n",
    "can_image_label = np.load('../data/dcgan/Fuzzy_image_label.npy')\n",
    "features = torch.tensor(can_image, dtype=torch.float32)\n",
    "features = features.reshape(-1, 1, 48, 48)\n",
    "labels = torch.tensor(can_image_label, dtype=torch.float32)  #MSELoss -> torch.float32\n",
    "distribution_calculate(netD, features, labels)\n",
    "test_p(netD, features, labels, 0.5)\n",
    "print('gear attack')\n",
    "can_image = np.load(\"../data/dcgan/gear_image_data.npy\")\n",
    "can_image_label = np.load('../data/dcgan/gear_image_label.npy')\n",
    "features = torch.tensor(can_image, dtype=torch.float32)\n",
    "features = features.reshape(-1, 1, 48, 48)\n",
    "labels = torch.tensor(can_image_label, dtype=torch.float32)  #MSELoss -> torch.float32\n",
    "distribution_calculate(netD, features, labels)\n",
    "test_p(netD, features, labels, 0.5)\n",
    "print('RPM attack')\n",
    "can_image = np.load(\"../data/dcgan/RPM_image_data.npy\")\n",
    "can_image_label = np.load('../data/dcgan/RPM_image_label.npy')\n",
    "features = torch.tensor(can_image, dtype=torch.float32)\n",
    "features = features.reshape(-1, 1, 48, 48)\n",
    "labels = torch.tensor(can_image_label, dtype=torch.float32)  #MSELoss -> torch.float32\n",
    "distribution_calculate(netD, features, labels)\n",
    "test_p(netD, features, labels, 0.5)\n",
    "# #################################################################\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result of the second discriminator for unknown attacks\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_374034/2012849565.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;31m###################################################################################test for second discriminator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'result of the second discriminator for unknown attacks'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m \u001b[0msecond_D\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../model/DCGAN_D.pkl'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0msecond_D\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'DoS attack'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# ############################################gan trainning\n",
    "# Create the Discriminator\n",
    "# netD = Discriminator(ngpu).to(device)\n",
    "# # Handle multi-gpu if desired\n",
    "# if (device.type == 'cuda') and (ngpu > 1):\n",
    "#     netD = nn.DataParallel(netD, list(range(ngpu)))\n",
    "\n",
    "# netD.apply(weights_init)\n",
    "# optimizerD = optim.SGD(netD.parameters(), lr=lr)\n",
    "# optimizerG = optim.SGD(netG.parameters(), lr=lr)\n",
    "\n",
    "# normal_dataloader = DataLoader(dataset=normal_dataset, batch_size=64, shuffle=True)\n",
    "# real_img = Variable(torch.ones(64, dtype=float).to(device), requires_grad=False)\n",
    "# fake_img = Variable(torch.zeros(64, dtype=float).to(device), requires_grad=False)\n",
    "# training_flag = 0\n",
    "# g_max = 0\n",
    "# for i in range(num_epochs):\n",
    "#     G_ideas = Variable(torch.Tensor(np.random.normal(0, 1, (64, nz, 6, 6))).cuda(), requires_grad=False)\n",
    "#     for batch_id, (x_train, y_train) in enumerate(normal_dataloader):\n",
    "#         if training_flag == 0:\n",
    "#             print('epoch = ', i, 'train for D')\n",
    "#             if len(x_train) < 64:\n",
    "#                 continue\n",
    "#             x_train = x_train.to(device)\n",
    "#             G_paintings = netG(G_ideas).to(device).detach()  # fake painting from G (random ideas)\n",
    "#             prob_artist0 = netD(x_train)  # D try to increase this prob\n",
    "#             prob_artist1 = netD(G_paintings)  # D try to reduce this prob\n",
    "#             print('batch_id',batch_id)\n",
    "#             print('train for D, prob_artist0: ', prob_artist0.mean())\n",
    "#             print('train for D,prob_artist1: ', prob_artist1.mean())\n",
    "#             if(prob_artist1.mean() < 0.5) and (prob_artist0.mean()>0.5):\n",
    "#                 training_flag =1\n",
    "#             real_loss = criterion(prob_artist0.to(float).reshape(64), real_img)\n",
    "#             fake_loss = criterion(prob_artist1.to(float).reshape(64), fake_img)\n",
    "#             D_loss = real_loss +fake_loss\n",
    "#             optimizerD.zero_grad()\n",
    "#             D_loss.backward()\n",
    "#             optimizerD.step()\n",
    "#         while(1):\n",
    "#             print('epoch = ', i, 'train for G')\n",
    "#             if len(x_train) < 64:\n",
    "#                 break\n",
    "#             G_paintings = netG(G_ideas).to(device)  # fake painting from G (random ideas)\n",
    "#             prob_artist1 = netD(G_paintings)\n",
    "#             print('batch_id: ', batch_id,' train for G,prob_artist1: ', prob_artist1.mean())\n",
    "#             if(prob_artist1.mean() >0.5):\n",
    "#                 training_flag =0\n",
    "#                 break\n",
    "#             g_max = g_max +1\n",
    "#             if g_max>300:\n",
    "#                 training_flag = 0\n",
    "#                 g_max=0\n",
    "#                 break\n",
    "#             G_loss = criterion(prob_artist1.to(float).reshape(64), real_img)\n",
    "#             optimizerG.zero_grad()\n",
    "#             G_loss.backward()\n",
    "#             optimizerG.step()\n",
    "# torch.save(netD, '../model/DCGAN_D.pkl')\n",
    "# torch.save(netG, '../model/DCGAN_G.pkl')\n",
    "##############################################################################\n",
    "###################################################################################test for second discriminator\n",
    "print('result of the second discriminator for unknown attacks')\n",
    "second_D = torch.load('../model/DCGAN_D.pkl')\n",
    "second_D.to('cpu')\n",
    "print('DoS attack')\n",
    "can_image = np.load(\"../data/dcgan/DoS_image_data.npy\")\n",
    "can_image_label = np.load('../data/dcgan/DoS_image_label.npy')\n",
    "features = torch.tensor(can_image, dtype=torch.float32)\n",
    "features = features.reshape(-1, 1, 48, 48)\n",
    "labels = torch.tensor(can_image_label, dtype=torch.float32)  #MSELoss -> torch.float32\n",
    "distribution_calculate(second_D, features, labels)\n",
    "test_p(second_D, features, labels, 0.5)\n",
    "print('Fuzzy attack')\n",
    "can_image = np.load(\"../data/dcgan/Fuzzy_image_data.npy\")\n",
    "can_image_label = np.load('../data/dcgan/Fuzzy_image_label.npy')\n",
    "features = torch.tensor(can_image, dtype=torch.float32)\n",
    "features = features.reshape(-1, 1, 48, 48)\n",
    "labels = torch.tensor(can_image_label, dtype=torch.float32)  #MSELoss -> torch.float32\n",
    "distribution_calculate(second_D, features, labels)\n",
    "test_p(second_D, features, labels, 0.5)\n",
    "print('gear attack')\n",
    "can_image = np.load(\"../data/dcgan/gear_image_data.npy\")\n",
    "can_image_label = np.load('../data/dcgan/gear_image_label.npy')\n",
    "features = torch.tensor(can_image, dtype=torch.float32)\n",
    "features = features.reshape(-1, 1, 48, 48)\n",
    "labels = torch.tensor(can_image_label, dtype=torch.float32)  #MSELoss -> torch.float32\n",
    "distribution_calculate(second_D, features, labels)\n",
    "test_p(second_D, features, labels, 0.5)\n",
    "print('RPM attack')\n",
    "can_image = np.load(\"../data/dcgan/RPM_image_data.npy\")\n",
    "can_image_label = np.load('../data/dcgan/RPM_image_label.npy')\n",
    "features = torch.tensor(can_image, dtype=torch.float32)\n",
    "features = features.reshape(-1, 1, 48, 48)\n",
    "labels = torch.tensor(can_image_label, dtype=torch.float32)  #MSELoss -> torch.float32\n",
    "distribution_calculate(second_D, features, labels)\n",
    "test_p(second_D, features, labels, 0.5)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a07c7f2cb6854cb74760151df50963b8a0c83fd1e2514d9f35420e11444faa08"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('pytorch_1.7.0': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
